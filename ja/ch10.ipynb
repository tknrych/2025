{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "ADPET68xjlzr",
    "tags": []
   },
   "source": [
    "# 第10章: 事前学習済み言語モデル（GPT型）\n",
    "\n",
    "本章では、GPT型（Transformerのデコーダ型）の事前学習済みモデルを利用して、言語生成、評判分析器（ポジネガ分類器）の構築、ファインチューニング、強化学習などに取り組む。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "C1xKmMckti92",
    "tags": []
   },
   "source": [
    "## 90. 次単語予測\n",
    "\n",
    "“The movie was full of\"に続くトークン（トークン列ではなく一つのトークンであることに注意せよ）として適切なもの上位10個と、その確率（尤度）を求めよ。ただし、言語モデルへのプロンプトがどのようなトークン列に変換されたか、確認せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.10 environment at: /Users/ryuichi/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m16 packages\u001b[0m \u001b[2min 1.87s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m7 packages\u001b[0m \u001b[2min 2.17s\u001b[0m\u001b[0m                                             \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m7 packages\u001b[0m \u001b[2min 39ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistro\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjiter\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.77.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      "\u001b[2mUsing Python 3.11.10 environment at: /Users/ryuichi/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 329ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 77ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 40ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      "\u001b[2mUsing Python 3.11.10 environment at: /Users/ryuichi/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m7 packages\u001b[0m \u001b[2min 677ms\u001b[0m\u001b[0m                                         \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 441ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 29ms\u001b[0m\u001b[0m                                 \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.9.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install openai\n",
    "!uv pip install python-dotenv\n",
    "!uv pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .envファイルをロードして環境変数を読み込む\n",
    "load_dotenv()\n",
    "\n",
    "# 環境変数から値を取得\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# 必須の環境変数が欠けている場合エラーをスロー\n",
    "if not azure_endpoint or not api_key or not api_version:\n",
    "    raise ValueError(\"必須の環境変数の値が取得できていません。環境変数を確認してください。\")\n",
    "\n",
    "# Azure OpenAI Clientの初期化\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=api_version\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "「'The movie was full of'」に続くトークン上位10個と、その確率（尤度）を求めよ。\n",
      "ただし、言語モデルへのプロンプトがどのようなトークン列に変換されたか、確認せよ。\n",
      "\n",
      "--- プロンプトのトークン化結果 ---\n",
      "元のプロンプト: 'The movie was full of'\n",
      "トークンID列: [976, 8249, 673, 3149, 328]\n",
      "トークンテキスト列: ['The', ' movie', ' was', ' full', ' of']\n",
      "トークン数: 5\n",
      "\n",
      "--- 続くトークン候補と確率 ---\n",
      "API呼び出しで実際に生成された最初のトークン (max_tokens=1 の結果): 'The'\n",
      "\n",
      "'The movie was full of' に続く位置でのトークン候補上位10件とその確率:\n",
      "  'The': 0.17045\n",
      "  'It': 0.00539\n",
      "  'Could': 0.00303\n",
      "  'intr': 0.00096\n",
      "  'st': 0.00054\n",
      "  'unexpected': 0.0003\n",
      "  'em': 0.0003\n",
      "  'Can': 0.00017\n",
      "  'v': 0.0001\n",
      "  'spect': 0.0001\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import tiktoken # tiktoken ライブラリをインポート\n",
    "\n",
    "def fetch_top_tokens_and_probabilities(payload, system_message=\"あなたは優秀な映画の専門家です。\"):\n",
    "    \"\"\"\n",
    "    Azure OpenAIのモデルに対してプロンプトに続くトークンとその確率を取得します。\n",
    "\n",
    "    Parameters:\n",
    "        - payload (dict): モデル名、プロンプト、温度、top_kを含む辞書。\n",
    "        - system_message (str): システムメッセージ（デフォルト値あり）。\n",
    "\n",
    "    Returns:\n",
    "        tuple: (APIが実際に生成した最初のトークン文字列, 上位トークンとその確率のリスト)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # API呼び出し: 次のトークン予測\n",
    "        # logprobs=True に加えて、top_logprobs パラメータを追加\n",
    "        response = client.chat.completions.create(\n",
    "            model=payload[\"model\"],\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": payload[\"prompt\"]}\n",
    "            ],\n",
    "            temperature=payload[\"temperature\"],\n",
    "            max_tokens=1, # 続く「一つの」トークンを見るため max_tokens=1\n",
    "            logprobs=True,\n",
    "            top_logprobs=payload[\"top_k\"] # 返却する上位トークン数を指定\n",
    "        )\n",
    "\n",
    "        # print(f\"APIレスポンス: {response}\") # デバッグが必要な場合のみ表示推奨\n",
    "\n",
    "        response_dict = response.model_dump()\n",
    "\n",
    "        # max_tokens=1 なので、生成された最初のトークンを取得\n",
    "        generated_token_text = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # 上位トークンとその確率を取得\n",
    "        # logprobs -> content -> [0] (最初の出力トークン) -> top_logprobs にアクセス\n",
    "        # top_logprobs はリスト内の辞書です: [{'token': ' abc', 'logprob': -0.1, 'bytes': [...]}, ...]\n",
    "        # content リストが空でないかチェック（max_tokens=1なので通常は1つの要素があるはず）\n",
    "        if not response_dict[\"choices\"][0].get(\"logprobs\") or not response_dict[\"choices\"][0][\"logprobs\"].get(\"content\"):\n",
    "             print(\"警告: APIレスポンスにlogprobs情報が含まれていませんでした。\")\n",
    "             return generated_token_text, []\n",
    "\n",
    "        # 最初の生成トークン位置での上位候補トークン情報を取得\n",
    "        top_logprobs_list_of_dicts = response_dict[\"choices\"][0][\"logprobs\"][\"content\"][0][\"top_logprobs\"]\n",
    "\n",
    "        if not top_logprobs_list_of_dicts:\n",
    "             print(\"警告: APIから上位トークン情報が返されませんでした。top_logprobs=0 の可能性があります。\")\n",
    "             return generated_token_text, []\n",
    "\n",
    "\n",
    "        top_tokens_and_probabilities = [\n",
    "            (token_info[\"token\"], round(pow(10, token_info[\"logprob\"]), 5))\n",
    "            for token_info in top_logprobs_list_of_dicts\n",
    "        ]\n",
    "\n",
    "        # APIが top_logprobs で指定した数のトークンを確率付きで返しているので、ソートして返します\n",
    "        return generated_token_text, sorted(top_tokens_and_probabilities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API呼び出し中にエラーが発生しました: {e}\")\n",
    "        # エラー発生時は生成されたトークンも確率リストも取得できない\n",
    "        return None, None\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o\",  # あなたのAzure OpenAIでデプロイしたモデルのデプロイメント名を指定\n",
    "    # \"prompt\": \"The movie was full of\",\n",
    "    \"prompt\": \"The movie was full of\",\n",
    "    \"temperature\": 0.7, # Temperature affects sampling of the *generated* token, but logprobs shows potential options regardless.\n",
    "    \"top_k\": 10 # APIに返すように要求する上位トークンの数\n",
    "}\n",
    "\n",
    "print(f\"「'{payload['prompt']}'」に続くトークン上位{payload['top_k']}個と、その確率（尤度）を求めよ。\")\n",
    "print(f\"ただし、言語モデルへのプロンプトがどのようなトークン列に変換されたか、確認せよ。\")\n",
    "\n",
    "# --- プロンプトのトークン化を表示 ---\n",
    "print(\"\\n--- プロンプトのトークン化結果 ---\")\n",
    "try:\n",
    "    # モデル名に対応するエンコーディングを取得\n",
    "    encoding = tiktoken.encoding_for_model(payload[\"model\"])\n",
    "\n",
    "    # プロンプトをトークンIDのリストにエンコード\n",
    "    input_token_ids = encoding.encode(payload[\"prompt\"])\n",
    "\n",
    "    # 各トークンIDを元のテキストに戻す（デコード）\n",
    "    # 各IDごとにデコードすると、元の区切り（スペースなど）を維持しやすい\n",
    "    input_tokens_text = [encoding.decode([token_id]) for token_id in input_token_ids]\n",
    "\n",
    "    print(f\"元のプロンプト: '{payload['prompt']}'\")\n",
    "    print(f\"トークンID列: {input_token_ids}\")\n",
    "    print(f\"トークンテキスト列: {input_tokens_text}\")\n",
    "    print(f\"トークン数: {len(input_token_ids)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"プロンプトのトークン化中にエラーが発生しました: {e}\")\n",
    "    print(\"tiktoken がインストールされているか確認してください (`pip install tiktoken`)。\")\n",
    "\n",
    "\n",
    "# --- 続くトークンの確率を取得 ---\n",
    "print(\"\\n--- 続くトークン候補と確率 ---\")\n",
    "# APIを呼び出して続くトークンの確率を取得\n",
    "generated_token, top_tokens_and_probabilities = fetch_top_tokens_and_probabilities(payload)\n",
    "\n",
    "# 結果を表示\n",
    "if generated_token is not None and top_tokens_and_probabilities is not None:\n",
    "    # API呼び出しによって実際に生成された最初のトークン\n",
    "    # これは logprobs リストに含まれる可能性が高いですが、サンプリングによる結果です。\n",
    "    print(f\"API呼び出しで実際に生成された最初のトークン (max_tokens=1 の結果): '{generated_token}'\")\n",
    "\n",
    "    print(f\"\\n'{payload['prompt']}' に続く位置でのトークン候補上位{payload['top_k']}件とその確率:\")\n",
    "    if top_tokens_and_probabilities:\n",
    "        # 確率の高い順に表示\n",
    "        for token, probability in top_tokens_and_probabilities:\n",
    "            print(f\"  '{token}': {probability}\") # トークンを引用符で囲むと見やすい\n",
    "    else:\n",
    "        print(\"上位トークン候補情報は取得できませんでした。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "s1RhOldA0meh",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 91. 続きのテキストの予測\n",
    "\n",
    "“The movie was full of\"に続くテキストを複数予測せよ。このとき、デコーディングの方法や温度パラメータ（temperature）を変えながら、予測される複数のテキストの変化を観察せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 課題 ===\n",
      "「'The movie was full of'」に続くテキストを複数予測し、デコーディング方法（温度、top_p）による変化を観察する。\n",
      "モデル: gpt-4o\n",
      "生成最大トークン数: 100\n",
      "============\n",
      "\n",
      "=== テキスト補完の生成と観察 ===\n",
      "\n",
      "--- 設定: 温度=0.0 (決定論的サンプリング) ---\n",
      "  補完 1:\n",
      "    The movie was full of **unexpected twists**, **emotional depth**, and\n",
      "    **stunning visuals** that kept the audience engaged from start to finish.\n",
      "    Whether it was the gripping storyline, the well-developed characters, or the\n",
      "    breathtaking cinematography, it delivered an unforgettable experience. What\n",
      "    kind of movie are you referring to?\n",
      "  補完 2:\n",
      "    The movie was full of **unexpected twists**, **emotional depth**, and\n",
      "    **stunning visuals** that kept the audience engaged from start to finish.\n",
      "    Whether it was the gripping storyline, the well-developed characters, or the\n",
      "    breathtaking cinematography, it delivered an unforgettable experience. What\n",
      "    kind of movie are you referring to?\n",
      "  補完 3:\n",
      "    The movie was full of **unexpected twists**, **emotional depth**, and\n",
      "    **stunning visuals** that kept the audience engaged from start to finish.\n",
      "    Whether it was the gripping storyline, the well-developed characters, or the\n",
      "    breathtaking cinematography, it delivered an unforgettable experience. What\n",
      "    kind of movie are you referring to?\n",
      "\n",
      "--- 設定: 温度=0.7, top_p=0.1 ---\n",
      "  補完 1:\n",
      "    The movie was full of **unexpected twists and turns**, keeping the audience\n",
      "    on the edge of their seats. It delivered a mix of **emotional depth**,\n",
      "    **thrilling action**, and **stunning visuals**, making it a memorable\n",
      "    experience. Whether it was the **complex characters**, the **heart-pounding\n",
      "    suspense**, or the **thought-provoking themes**, it left viewers with plenty\n",
      "    to think about long after the credits rolled.\n",
      "  補完 2:\n",
      "    The movie was full of **unexpected twists and turns**, keeping the audience\n",
      "    on the edge of their seats. It delivered a mix of **emotional depth**,\n",
      "    **thrilling action**, and **stunning visuals**, making it a memorable\n",
      "    experience. Whether it was the **complex characters**, the **heart-pounding\n",
      "    suspense**, or the **thought-provoking themes**, it left viewers with plenty\n",
      "    to think about long after the credits rolled.\n",
      "  補完 3:\n",
      "    The movie was full of **unexpected twists and turns**, keeping the audience\n",
      "    on the edge of their seats. It delivered a mix of **emotional depth**,\n",
      "    **thrilling action**, and **stunning visuals**, making it a memorable\n",
      "    experience. Whether it was the **complex characters**, the **heart-pounding\n",
      "    suspense**, or the **thought-provoking themes**, it left viewers with plenty\n",
      "    to think about long after the credits rolled.\n",
      "\n",
      "--- 設定: 温度=0.7, top_p=0.5 ---\n",
      "  補完 1:\n",
      "    unexpected twists and emotional depth, leaving the audience captivated and\n",
      "    on the edge of their seats.\n",
      "  補完 2:\n",
      "    unexpected twists and turns, captivating moments, and emotional depth that\n",
      "    kept the audience on the edge of their seats. It blended drama, suspense,\n",
      "    and humor seamlessly, leaving a lasting impression.\n",
      "  補完 3:\n",
      "    unexpected twists and turns, captivating moments, and emotional depth that\n",
      "    kept the audience on the edge of their seats. It masterfully blended drama,\n",
      "    suspense, and humor, leaving a lasting impression long after the credits\n",
      "    rolled.\n",
      "\n",
      "--- 設定: 温度=0.7, top_p=1.0 ---\n",
      "  補完 1:\n",
      "    The movie was full of twists and turns, keeping the audience on the edge of\n",
      "    their seats. It had moments of intense drama, heartfelt emotion, and\n",
      "    unexpected surprises that made it a memorable experience. Whether it was the\n",
      "    captivating performances, the stunning visuals, or the gripping storyline,\n",
      "    it offered something for everyone to enjoy.\n",
      "  補完 2:\n",
      "    The movie was full of **unexpected twists and turns** that kept the audience\n",
      "    on the edge of their seats. Whether it was the gripping storyline,\n",
      "    compelling performances, or stunning visuals, it delivered a memorable\n",
      "    experience. What kind of movie are you thinking of?\n",
      "  補完 3:\n",
      "    unexpected twists and gripping moments that kept the audience on the edge of\n",
      "    their seats! Could you share more details about the movie or what stood out\n",
      "    to you?\n",
      "\n",
      "--- 設定: 温度=1.0, top_p=0.1 ---\n",
      "  補完 1:\n",
      "    The movie was full of **unexpected twists**, **emotional depth**, and\n",
      "    **stunning visuals** that kept the audience engaged from start to finish.\n",
      "    Whether it was the gripping storyline, the well-developed characters, or the\n",
      "    breathtaking cinematography, it delivered an unforgettable experience. What\n",
      "    kind of movie are you referring to?\n",
      "  補完 2:\n",
      "    The movie was full of **unexpected twists**, **emotional depth**, and\n",
      "    **stunning visuals** that kept the audience engaged from start to finish.\n",
      "    Whether it was the gripping storyline, the well-developed characters, or the\n",
      "    breathtaking cinematography, it delivered an unforgettable experience. What\n",
      "    kind of movie are you referring to?\n",
      "  補完 3:\n",
      "    The movie was full of **unexpected twists**, **emotional depth**, and\n",
      "    **stunning visuals** that kept the audience engaged from start to finish.\n",
      "    Whether it was the gripping storyline, the well-developed characters, or the\n",
      "    breathtaking cinematography, it delivered an unforgettable experience. What\n",
      "    kind of movie are you referring to?\n",
      "\n",
      "--- 設定: 温度=1.0, top_p=0.5 ---\n",
      "  補完 1:\n",
      "    unexpected twists and turns, keeping the audience on the edge of their\n",
      "    seats. The gripping storyline, combined with stellar performances and\n",
      "    stunning visuals, made it an unforgettable experience.\n",
      "  補完 2:\n",
      "    unexpected twists and turns, keeping the audience on the edge of their\n",
      "    seats. The gripping storyline, coupled with strong performances and stunning\n",
      "    visuals, made it an unforgettable experience.\n",
      "  補完 3:\n",
      "    unexpected twists and turns, keeping the audience on the edge of their\n",
      "    seats. The gripping storyline, combined with stellar performances and\n",
      "    stunning visuals, made it an unforgettable experience.\n",
      "\n",
      "--- 設定: 温度=1.0, top_p=1.0 ---\n",
      "  補完 1:\n",
      "    suspenseful twists and turns! It kept the audience on the edge of their\n",
      "    seats, delivering unexpected surprises and emotional moments that left a\n",
      "    lasting impression. Do you want to discuss a specific scene or theme from\n",
      "    the movie?\n",
      "  補完 2:\n",
      "    suspense and unexpected twists, keeping the audience on the edge of their\n",
      "    seats. The plot was intricately woven, and the characters were compelling,\n",
      "    making it a rollercoaster of emotions. Whether it was the dramatic tension\n",
      "    or the moments of relief, the movie delivered a truly immersive experience.\n",
      "  補完 3:\n",
      "    suspense and unexpected twists that kept the audience on the edge of their\n",
      "    seats. From the gripping performances of the cast to the stunning visuals,\n",
      "    every element came together to deliver a compelling cinematic experience.\n",
      "\n",
      "--- 設定: 温度=1.5, top_p=0.1 ---\n",
      "  補完 1:\n",
      "    The movie was full of **unexpected twists and turns**, keeping the audience\n",
      "    on the edge of their seats. It delivered a mix of **emotional depth**,\n",
      "    **thrilling action**, and **stunning visuals**, making it a memorable\n",
      "    experience. Whether it was the **complex characters**, the **heart-pounding\n",
      "    suspense**, or the **thought-provoking themes**, it left viewers with plenty\n",
      "    to think about long after the credits rolled.\n",
      "  補完 2:\n",
      "    The movie was full of **unexpected twists and turns**, keeping the audience\n",
      "    on the edge of their seats. It delivered a mix of **emotional depth**,\n",
      "    **thrilling action**, and **stunning visuals**, making it a memorable\n",
      "    experience. Whether it was the **complex characters**, the **heart-pounding\n",
      "    suspense**, or the **thought-provoking themes**, it left viewers with plenty\n",
      "    to think about long after the credits rolled.\n",
      "  補完 3:\n",
      "    The movie was full of **unexpected twists and turns**, keeping the audience\n",
      "    on the edge of their seats. It delivered a mix of **emotional depth**,\n",
      "    **thrilling action**, and **stunning visuals**, making it a memorable\n",
      "    experience. Whether it was the **complex characters**, the **heart-pounding\n",
      "    suspense**, or the **thought-provoking themes**, it left viewers with plenty\n",
      "    to think about long after the credits rolled.\n",
      "\n",
      "--- 設定: 温度=1.5, top_p=0.5 ---\n",
      "  補完 1:\n",
      "    unexpected twists and turns, keeping the audience on the edge of their\n",
      "    seats. The characters were well-developed, and the plot was layered with\n",
      "    emotional depth, humor, and suspense. It was truly a rollercoaster of\n",
      "    emotions from start to finish!\n",
      "  補完 2:\n",
      "    unexpected twists and emotional depth, keeping the audience on the edge of\n",
      "    their seats. The stunning visuals and compelling performances added layers\n",
      "    to the storytelling, making it a truly unforgettable experience.\n",
      "  補完 3:\n",
      "    The movie was full of **suspense**, **action**, and **unexpected twists**\n",
      "    that kept the audience on the edge of their seats. Whether it was the\n",
      "    emotional depth of the characters, the breathtaking visuals, or the gripping\n",
      "    storyline, it delivered a truly unforgettable experience.\n",
      "\n",
      "--- 設定: 温度=1.5, top_p=1.0 ---\n",
      "  補完 1:\n",
      "    dramatic twists, emotional depth, and stunning visuals. It kept you hooked\n",
      "    until the very end! What movie are you referring to?\n",
      "  補完 2:\n",
      "    \"The movie was full of intense moments, unpredictable twists, and deep\n",
      "    emotions.\"    Hope you're referring to something specific—curious to hear if\n",
      "    this lyric of the suggestion strikes at кyou feedback provides :]?\n",
      "  補完 3:\n",
      "    suspense, thrilling action scenes, and unexpected twists that kept the\n",
      "    audience on edge. It had an emotionally gripping narrative complemented by\n",
      "    outstanding performances and a captivating soundtrack that elevated the\n",
      "    entire experience. Is this about a particular movie you'd like to discuss\n",
      "    more?\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import tiktoken\n",
    "import os # 環境変数からAPIキーなどを読み込む場合に使用\n",
    "\n",
    "# --- テキスト補完生成関数 ---\n",
    "def generate_text_completions(client, model, prompt, max_tokens, temperature, top_p, n):\n",
    "    \"\"\"\n",
    "    指定されたパラメータでAzure OpenAIモデルから複数のテキスト補完を生成します。\n",
    "\n",
    "    Parameters:\n",
    "        - client: AzureOpenAI クライアントインスタンス\n",
    "        - model (str): モデル名\n",
    "        - prompt (str): 入力プロンプト\n",
    "        - max_tokens (int): 生成する最大トークン数 (1以上)\n",
    "        - temperature (float): サンプリング温度 (0.0-2.0)。0で決定論的。\n",
    "        - top_p (float): top_p サンプリング確率 (0.0-1.0)。1.0でtemperatureサンプリングに近い。\n",
    "        - n (int): 生成する補完の数 (1以上)\n",
    "\n",
    "    Returns:\n",
    "        list: 生成されたテキスト文字列のリスト。エラー発生時はエラーメッセージを含むリスト。\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        return [\"Error: Azure OpenAI client is not initialized.\"] * n\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            n=n, # 複数の補完を生成\n",
    "            # logprobs, top_logprobs はここでは使用しない\n",
    "        )\n",
    "\n",
    "        # 生成されたテキストをリストとして抽出\n",
    "        completions = [choice.message.content for choice in response.choices]\n",
    "\n",
    "        return completions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API呼び出し中にエラーが発生しました (温度={temperature}, top_p={top_p}): {e}\")\n",
    "        return [f\"Error generating completion: {e}\"] * n # エラー時はエラーメッセージを含むリストを返す\n",
    "\n",
    "# --- 主処理 ---\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "prompt_text = \"The movie was full of\"\n",
    "generate_max_tokens = 100 # 生成するテキストの最大長（トークン単位）。必要に応じて調整。\n",
    "\n",
    "# 試行する温度とtop_pの値のリスト\n",
    "# 温度 (Temperature): 高いほどランダム性が増す (多様だが脱線も)。低いほど決定論的 (毎回同じ傾向)。\n",
    "temperatures_to_test = [0.0, 0.7, 1.0, 1.5]\n",
    "# top_p (Nucleus Sampling): 累積確率が top_p になるまで確率の高いトークン候補を選び、その中からサンプリング。\n",
    "# 低いほど候補が絞られ予測可能に。高いほど候補が増え多様に (1.0 は temperature サンプリングに近い)。\n",
    "top_p_to_test = [0.1, 0.5, 1.0]\n",
    "\n",
    "# 各設定で生成するテキストの数\n",
    "num_completions_per_setting = 3 # 各温度・top_pの組み合わせで3つの補完を生成\n",
    "\n",
    "print(f\"=== 課題 ===\")\n",
    "print(f\"「'{prompt_text}'」に続くテキストを複数予測し、デコーディング方法（温度、top_p）による変化を観察する。\")\n",
    "print(f\"モデル: {model_name}\")\n",
    "print(f\"生成最大トークン数: {generate_max_tokens}\")\n",
    "print(\"============\")\n",
    "\n",
    "print(\"\\n=== テキスト補完の生成と観察 ===\")\n",
    "\n",
    "# 温度とtop_pの組み合わせごとに補完を生成\n",
    "for temp in temperatures_to_test:\n",
    "    for p in top_p_to_test:\n",
    "        # temperature=0.0 の場合、top_p は通常無視され決定論的なサンプリングになります。\n",
    "        # 重複を避けるため、temperature=0.0 の場合は top_p=1.0 の設定のみ実行します。\n",
    "        if temp == 0.0 and p != 1.0:\n",
    "            continue # 他の top_p はスキップ\n",
    "\n",
    "        # 設定の表示\n",
    "        if temp == 0.0:\n",
    "             print(f\"\\n--- 設定: 温度={temp} (決定論的サンプリング) ---\")\n",
    "        else:\n",
    "             print(f\"\\n--- 設定: 温度={temp}, top_p={p} ---\")\n",
    "\n",
    "        # テキスト補完を生成\n",
    "        completions = generate_text_completions(\n",
    "            client, # クライアントオブジェクトを渡す\n",
    "            model_name,\n",
    "            prompt_text,\n",
    "            generate_max_tokens,\n",
    "            temp,\n",
    "            p,\n",
    "            num_completions_per_setting\n",
    "        )\n",
    "\n",
    "        # 生成された補完を表示\n",
    "        for i, text in enumerate(completions):\n",
    "            print(f\"  補完 {i+1}:\")\n",
    "            # テキストを整形して表示\n",
    "            print(textwrap.fill(text, width=80, initial_indent='    ', subsequent_indent='    '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "7ZFadg6B8VdA",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 92. 予測されたテキストの確率を計算\n",
    "\n",
    "“The movie was full of\"に続くテキストを予測し、生成された各単語の尤度を表示せよ（生成されるテキストが長いと出力が読みにくくなるので、適当な長さで生成を打ち切るとよい）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 課題 ===\n",
      "「'The movie was full of'」に続くテキストを予測し、生成された各トークンの尤度を表示する。\n",
      "モデル: gpt-4o\n",
      "生成最大トークン数: 30\n",
      "============\n",
      "\n",
      "--- 元のプロンプトのトークン化結果 ---\n",
      "元のプロンプト: 'The movie was full of'\n",
      "トークンID列: [976, 8249, 673, 3149, 328]\n",
      "トークンテキスト列: ['The', ' movie', ' was', ' full', ' of']\n",
      "トークン数: 5\n",
      "\n",
      "=== 生成されたテキストとそのトークン確率 ===\n",
      "\n",
      "生成されたテキスト (最大30トークン):\n",
      "    The movie was full of **unexpected twists** and **emotional depth**, keeping\n",
      "    the audience engaged from start to finish. It blended moments of intense\n",
      "    drama\n",
      "\n",
      "各生成トークンとその確率:\n",
      "  トークン: 'The'          , 確率: 0.29954\n",
      "  トークン: ' movie'       , 確率: 0.99663\n",
      "  トークン: ' was'         , 確率: 0.99999\n",
      "  トークン: ' full'        , 確率: 1.0\n",
      "  トークン: ' of'          , 確率: 1.0\n",
      "  トークン: ' **'          , 確率: 0.57547\n",
      "  トークン: 'unexpected'   , 確率: 0.53364\n",
      "  トークン: ' twists'      , 確率: 0.99525\n",
      "  トークン: '**'           , 確率: 0.31889\n",
      "  トークン: ' and'         , 確率: 0.94333\n",
      "  トークン: ' **'          , 確率: 0.96054\n",
      "  トークン: 'em'           , 確率: 0.57162\n",
      "  トークン: 'otional'      , 確率: 0.99956\n",
      "  トークン: ' depth'       , 確率: 0.8926\n",
      "  トークン: '**,'          , 確率: 0.87804\n",
      "  トークン: ' keeping'     , 確率: 0.7553\n",
      "  トークン: ' the'         , 確率: 0.83831\n",
      "  トークン: ' audience'    , 確率: 0.99972\n",
      "  トークン: ' engaged'     , 確率: 0.58211\n",
      "  トークン: ' from'        , 確率: 0.87171\n",
      "  トークン: ' start'       , 確率: 0.96651\n",
      "  トークン: ' to'          , 確率: 1.0\n",
      "  トークン: ' finish'      , 確率: 0.99998\n",
      "  トークン: '.'            , 確率: 0.99616\n",
      "  トークン: ' It'          , 確率: 0.31441\n",
      "  トークン: ' blended'     , 確率: 0.18124\n",
      "  トークン: ' moments'     , 確率: 0.2577\n",
      "  トークン: ' of'          , 確率: 1.0\n",
      "  トークン: ' intense'     , 確率: 0.36998\n",
      "  トークン: ' drama'       , 確率: 0.63115\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import tiktoken\n",
    "import os\n",
    "import math # logprob（対数確率）を通常の確率に変換するためにmathモジュールを使用\n",
    "\n",
    "# --- テキスト生成と確率取得関数 ---\n",
    "def generate_text_with_probabilities(client, model, prompt, max_tokens):\n",
    "    \"\"\"\n",
    "    プロンプトに続くテキストを生成し、各生成トークンの確率を返します。\n",
    "\n",
    "    Parameters:\n",
    "        - client: 初期化済みの AzureOpenAI クライアントインスタンス\n",
    "        - model (str): Azureでデプロイしたモデルのデプロイメント名\n",
    "        - prompt (str): 入力プロンプト\n",
    "        - max_tokens (int): 生成する最大トークン数 (1以上)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (生成されたテキスト文字列, 各トークンと確率のリスト)。\n",
    "               エラー発生時は (None, None)。\n",
    "    \"\"\"\n",
    "    if client is None:\n",
    "        print(\"エラー: OpenAI client is not initialized. Cannot make API call.\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        # API呼び出し: テキスト生成とトークン確率の取得\n",
    "        # temperature は 0.0 (決定論的) を推奨 - 最も尤もらしいシーケンスが生成される\n",
    "        # n=1 で単一の補完を取得\n",
    "        # logprobs=True で生成トークンそれぞれの確率を要求\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.0, # 確率を観察しやすくするため決定論的にする\n",
    "            n=1,             # 1つの補完を取得\n",
    "            logprobs=True    # 生成トークンの確率情報を取得\n",
    "            # top_p, top_logprobs は今回は使用しない\n",
    "        )\n",
    "\n",
    "        # print(f\"APIレスポンス: {response}\") # 必要に応じてデバッグ用にコメント解除\n",
    "\n",
    "        response_dict = response.model_dump()\n",
    "\n",
    "        # 生成されたテキスト全体を取得 (choices[0] は n=1 なので最初の要素)\n",
    "        generated_text = response_dict[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # logprobs 情報があるか確認\n",
    "        # logprobs=True にしても、生成テキストがない場合など content が None になる可能性あり\n",
    "        logprobs_info = response_dict[\"choices\"][0].get(\"logprobs\")\n",
    "        if not logprobs_info or not logprobs_info.get(\"content\"):\n",
    "             print(\"警告: APIレスポンスにlogprobs情報が含まれていませんでした。\")\n",
    "             # テキスト自体は返せたかもしれないが、確率は不明\n",
    "             return generated_text, []\n",
    "\n",
    "        # 生成された各トークンとそのlogprobを取得\n",
    "        token_logprob_list = logprobs_info[\"content\"]\n",
    "\n",
    "        # 各トークンと確率のリストを作成\n",
    "        token_probability_list = []\n",
    "        for token_info in token_logprob_list:\n",
    "             token_text = token_info[\"token\"]\n",
    "             logprob = token_info[\"logprob\"]\n",
    "             # logprob (対数確率) を通常の確率に変換\n",
    "             # OpenAI API の logprob は自然対数 (底 e) です\n",
    "             probability = math.exp(logprob)\n",
    "             # 確率を小数点以下5桁で丸める\n",
    "             token_probability_list.append((token_text, round(probability, 5)))\n",
    "\n",
    "        return generated_text, token_probability_list\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"API呼び出し中にエラーが発生しました: {e}\")\n",
    "        # エラー発生時はテキストも確率も取得できていない\n",
    "        return None, None\n",
    "\n",
    "# --- 主処理 ---\n",
    "\n",
    "model_name = \"gpt-4o\" # あなたのAzure OpenAIでデプロイしたモデルのデプロイメント名を指定\n",
    "prompt_text = \"The movie was full of\"\n",
    "generate_max_tokens_limit = 30 # 生成を打ち切る最大トークン数（適当な長さ）\n",
    "\n",
    "print(f\"=== 課題 ===\")\n",
    "print(f\"「'{prompt_text}'」に続くテキストを予測し、生成された各トークンの尤度を表示する。\")\n",
    "print(f\"モデル: {model_name}\")\n",
    "print(f\"生成最大トークン数: {generate_max_tokens_limit}\")\n",
    "print(\"============\")\n",
    "\n",
    "# --- 元のプロンプトのトークン化を表示 (参考情報として維持) ---\n",
    "print(\"\\n--- 元のプロンプトのトークン化結果 ---\")\n",
    "# tiktoken は API クライアント初期化の成功とは独立して動作\n",
    "# ただし、モデル名がtiktokenでサポートされている必要がある\n",
    "try:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    input_token_ids = encoding.encode(prompt_text)\n",
    "    input_tokens_text = [encoding.decode([token_id]) for token_id in input_token_ids]\n",
    "\n",
    "    print(f\"元のプロンプト: '{prompt_text}'\")\n",
    "    print(f\"トークンID列: {input_token_ids}\")\n",
    "    print(f\"トークンテキスト列: {input_tokens_text}\")\n",
    "    print(f\"トークン数: {len(input_token_ids)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"プロンプトのトークン化中にエラーが発生しました: {e}\")\n",
    "    print(\"モデル名が正しいか、tiktoken がインストールされているか確認してください (`pip install tiktoken`)。\")\n",
    "\n",
    "\n",
    "print(\"\\n=== 生成されたテキストとそのトークン確率 ===\")\n",
    "\n",
    "# テキストを生成し、各トークンの確率を取得\n",
    "# generate_text_with_probabilities 関数内でクライアント初期化の成功をチェック\n",
    "generated_text, token_probabilities = generate_text_with_probabilities(\n",
    "    client, # 初期化されたクライアントを渡す\n",
    "    model_name,\n",
    "    prompt_text,\n",
    "    generate_max_tokens_limit\n",
    ")\n",
    "\n",
    "# 結果を表示\n",
    "if generated_text is not None:\n",
    "    print(f\"\\n生成されたテキスト (最大{generate_max_tokens_limit}トークン):\")\n",
    "    # 生成テキスト全体を表示\n",
    "    print(textwrap.fill(generated_text, width=80, initial_indent='    ', subsequent_indent='    '))\n",
    "\n",
    "    if token_probabilities:\n",
    "        print(\"\\n各生成トークンとその確率:\")\n",
    "        # 各トークンと確率を表示\n",
    "        # 見やすくするために、トークンを repr() で囲み、確率を調整して表示\n",
    "        # repr() を使うと '\\n', '\\t', ' ' (スペース) など、トークンの厳密な内容が見える\n",
    "        for token, probability in token_probabilities:\n",
    "             display_token = repr(token)\n",
    "             # 表示を揃えるために幅を指定 (必要に応じて調整)\n",
    "             print(f\"  トークン: {display_token:<15}, 確率: {probability}\")\n",
    "    else:\n",
    "        print(\"\\nトークン確率情報は取得できませんでした。（API呼び出しエラーまたはlogprobs情報なし）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "FvNCTMj6OegF",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 93. パープレキシティ\n",
    "\n",
    "適当な文を準備して、事前学習済み言語モデルでパープレキシティを測定せよ。例えば、\n",
    "\n",
    "+ The movie was full of surprises\n",
    "+ The movies were full of surprises\n",
    "+ The movie were full of surprises\n",
    "+ The movies was full of surprises\n",
    "\n",
    "の4文に対して、パープレキシティを測定して観察せよ（最後の2つの文は故意に文法的な間違いを入れた）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 課題 ===\n",
      "与えられた文に対するパープレキシティを測定し、比較する。\n",
      "モデル: gpt-4o\n",
      "logprob取得のための上位K (API制限): 20\n",
      "API遅延: 0.01秒\n",
      "============\n",
      "\n",
      "=== パープレキシティ測定結果 ===\n",
      "  'The movie was full of surprises' (6トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' movie' (' movie') が上位 20 候補に見つかりませんでした (プロンプト: 'The')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' was' (' was') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' full' (' full') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie was')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' of' (' of') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie was full')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' surprises' (' surprises') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie was full of')。代用logprob (-20.0) を使用します。\n",
      "文: 'The movie was full of surprises'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'The movies were full of surprises' (6トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' movies' (' movies') が上位 20 候補に見つかりませんでした (プロンプト: 'The')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' were' (' were') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' full' (' full') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies were')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' of' (' of') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies were full')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' surprises' (' surprises') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies were full of')。代用logprob (-20.0) を使用します。\n",
      "文: 'The movies were full of surprises'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'The movie were full of surprises' (6トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' movie' (' movie') が上位 20 候補に見つかりませんでした (プロンプト: 'The')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' were' (' were') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' full' (' full') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie were')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' of' (' of') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie were full')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' surprises' (' surprises') が上位 20 候補に見つかりませんでした (プロンプト: 'The movie were full of')。代用logprob (-20.0) を使用します。\n",
      "文: 'The movie were full of surprises'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'The movies was full of surprises' (6トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' movies' (' movies') が上位 20 候補に見つかりませんでした (プロンプト: 'The')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' was' (' was') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' full' (' full') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies was')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' of' (' of') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies was full')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' surprises' (' surprises') が上位 20 候補に見つかりませんでした (プロンプト: 'The movies was full of')。代用logprob (-20.0) を使用します。\n",
      "文: 'The movies was full of surprises'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'Surprises full of was movie The' (7トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン 'prises' ('prises') が上位 20 候補に見つかりませんでした (プロンプト: 'Sur')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' full' (' full') が上位 20 候補に見つかりませんでした (プロンプト: 'Surprises')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' of' (' of') が上位 20 候補に見つかりませんでした (プロンプト: 'Surprises full')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' was' (' was') が上位 20 候補に見つかりませんでした (プロンプト: 'Surprises full of')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' movie' (' movie') が上位 20 候補に見つかりませんでした (プロンプト: 'Surprises full of was')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' The' (' The') が上位 20 候補に見つかりませんでした (プロンプト: 'Surprises full of was movie')。代用logprob (-20.0) を使用します。\n",
      "文: 'Surprises full of was movie The'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'This is a very common sentence' (6トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' is' (' is') が上位 20 候補に見つかりませんでした (プロンプト: 'This')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' a' (' a') が上位 20 候補に見つかりませんでした (プロンプト: 'This is')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' very' (' very') が上位 20 候補に見つかりませんでした (プロンプト: 'This is a')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' common' (' common') が上位 20 候補に見つかりませんでした (プロンプト: 'This is a very')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' sentence' (' sentence') が上位 20 候補に見つかりませんでした (プロンプト: 'This is a very common')。代用logprob (-20.0) を使用します。\n",
      "文: 'This is a very common sentence'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'This very is a common sentence' (6トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' very' (' very') が上位 20 候補に見つかりませんでした (プロンプト: 'This')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' is' (' is') が上位 20 候補に見つかりませんでした (プロンプト: 'This very')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' a' (' a') が上位 20 候補に見つかりませんでした (プロンプト: 'This very is')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' common' (' common') が上位 20 候補に見つかりませんでした (プロンプト: 'This very is a')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' sentence' (' sentence') が上位 20 候補に見つかりませんでした (プロンプト: 'This very is a common')。代用logprob (-20.0) を使用します。\n",
      "文: 'This very is a common sentence'\n",
      "パープレキシティ: 485165195.4098\n",
      "------------------------------\n",
      "  'The quick brown fox jumps over the lazy dog' (9トークン) のパープレキシティを計算中...\n",
      "  警告: 対象トークン ' quick' (' quick') が上位 20 候補に見つかりませんでした (プロンプト: 'The')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' brown' (' brown') が上位 20 候補に見つかりませんでした (プロンプト: 'The quick')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' fox' (' fox') が上位 20 候補に見つかりませんでした (プロンプト: 'The quick brown')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' jumps' (' jumps') が上位 20 候補に見つかりませんでした (プロンプト: 'The quick brown fox')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' over' (' over') が上位 20 候補に見つかりませんでした (プロンプト: 'The quick brown fox jumps')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' the' (' the') が上位 20 候補に見つかりませんでした (プロンプト: 'The quick brown fox jumps over')。代用logprob (-20.0) を使用します。\n",
      "  警告: 対象トークン ' dog' (' dog') が上位 20 候補に見つかりませんでした (プロンプト: 'The quick brown fox jumps over the lazy')。代用logprob (-20.0) を使用します。\n",
      "文: 'The quick brown fox jumps over the lazy dog'\n",
      "パープレキシティ: 203733994.0114\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import tiktoken\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "# --- パープレキシティ計算関数 ---\n",
    "# top_k_for_logprobs のデフォルト値を 20 に修正\n",
    "def calculate_perplexity(client, model, sentence, top_k_for_logprobs=20, delay_seconds=0.05):\n",
    "    \"\"\"\n",
    "    指定された文のパープレキシティを計算します。\n",
    "    文中の各トークンについて、その前のトークン列をプロンプトとしてAPIを呼び出し、\n",
    "    当該トークンの確率を取得します。\n",
    "\n",
    "    Parameters:\n",
    "        - client: 初期化済みの AzureOpenAI クライアントインスタンス\n",
    "        - model (str): Azureでデプロイしたモデルのデプロイメント名\n",
    "        - sentence (str): パープレキシティを測定する文\n",
    "        - top_k_for_logprobs (int): APIで取得する上位トークン確率の数。\n",
    "                                   モデルの制限により最大値は通常20です。\n",
    "                                   対象トークンがこの中に含まれる必要があります。\n",
    "        - delay_seconds (float): API呼び出し間の待ち時間（秒）。レート制限対策。\n",
    "\n",
    "    Returns:\n",
    "        float: 計算されたパープレキシティ。計算できない場合は float('inf')。\n",
    "    \"\"\"\n",
    "    # APIの top_logprobs の制限値を確認し、指定値がそれを超えていないかチェック（念のため）\n",
    "    actual_top_k = min(top_k_for_logprobs, 20) # API制限を考慮\n",
    "    if top_k_for_logprobs > 20:\n",
    "         print(f\"  警告: 指定された top_k_for_logprobs ({top_k_for_logprobs}) はモデルの上限 (20) を超えています。実際には {actual_top_k} を使用します。\")\n",
    "\n",
    "\n",
    "    if client is None:\n",
    "        print(\"エラー: OpenAI client is not initialized. Cannot calculate perplexity.\")\n",
    "        return float('inf')\n",
    "\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "        # 文全体をトークンIDに変換\n",
    "        sentence_token_ids = encoding.encode(sentence)\n",
    "        num_tokens = len(sentence_token_ids)\n",
    "\n",
    "        # 1トークン以下の文はパープレキシティ計算が定義されない（あるいは1となる）\n",
    "        if num_tokens <= 1:\n",
    "            print(f\"警告: 文 '{sentence}' のトークン数が1以下です ({num_tokens}トークン)。パープレキシティは定義されません。\")\n",
    "            return 1.0 if num_tokens == 1 else float('inf') # 1トークンの場合は通常1、0トークンは無限大\n",
    "\n",
    "        total_logprob = 0.0\n",
    "        num_terms = 0 # logprobを合計できた項の数\n",
    "\n",
    "        print(f\"  '{sentence}' ({num_tokens}トークン) のパープレキシティを計算中...\")\n",
    "\n",
    "        # 文の2番目のトークンから最後までループ (w_i | w_1...w_{i-1}) を取得するため\n",
    "        # ループ変数 i は、sentence_token_ids リストにおける次のトークンのインデックス\n",
    "        # プロンプトは sentence_token_ids[:i] となり、次のトークンは sentence_token_ids[i]\n",
    "        # i=1 から num_tokens-1 まで回す (sentence_token_ids[1] から sentence_token_ids[num_tokens-1] まで)\n",
    "        for i in range(1, num_tokens):\n",
    "            target_token_id = sentence_token_ids[i]\n",
    "            # 対象トークンをテキストにデコード (APIレスポンスのトークンと比較するため)\n",
    "            target_token_text = encoding.decode([target_token_id])\n",
    "\n",
    "            # プロンプトとして使用するトークン列 (対象トークンの直前まで)\n",
    "            prompt_token_ids = sentence_token_ids[:i]\n",
    "            prompt_text = encoding.decode(prompt_token_ids)\n",
    "\n",
    "            # プロンプトが空になる場合（文頭のトークンに対する確率）は、\n",
    "            # APIのlogprobs機能では直接取得が難しいため、2番目のトークンから開始しています。\n",
    "            # パープレキシティの定義によっては最初のトークンの確率も考慮しますが、\n",
    "            # 一般的なLM評価では2番目以降で計算することが多いです。\n",
    "            # ここでは i=1 から開始するため、最初のトークン(i=0)をプロンプトにした次のトークン(i=1)から評価します。\n",
    "            if not prompt_text: # 最初のトークンに対する評価の場合（i=0の時だが、ここではi=1から開始）\n",
    "                 # print(f\"  スキップ: 最初のトークン '{target_token_text}' の確率計算はスキップされます。\")\n",
    "                 # num_terms += 1 # 項数に含める場合はコメント解除（分母に影響）\n",
    "                 continue # ここでは i=1 からループしているので、i=0 のケースは発生しない\n",
    "\n",
    "\n",
    "            # API呼び出し: プロンプトに続く最初の1トークンの確率を取得\n",
    "            # temperature=0.0 で最も尤もらしい分布を取得しやすくする\n",
    "            # top_logprobs で対象トークンが分布に含まれる可能性を高める（ただし上限あり）\n",
    "            try:\n",
    "                api_response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\", \"content\": prompt_text}\n",
    "                    ],\n",
    "                    max_tokens=1, # 次の1トークンのみ予測\n",
    "                    temperature=0.0, # サンプリングのランダム性をなくす（確率分布は変わらない）\n",
    "                    logprobs=True, # ログ確率を要求\n",
    "                    top_logprobs=actual_top_k # 実際の制限値を適用\n",
    "                )\n",
    "\n",
    "                # API呼び出し間に遅延を入れる（レート制限対策）\n",
    "                time.sleep(delay_seconds)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  エラー: API呼び出し失敗 (プロンプト: '{prompt_text}'): {e}\")\n",
    "                # API呼び出しに失敗した場合は、計算不可として無限大を返す\n",
    "                return float('inf')\n",
    "\n",
    "\n",
    "            # レスポンスからログ確率情報を抽出\n",
    "            logprobs_info = api_response.choices[0].logprobs\n",
    "            # logprobs_info.content は生成トークンに関するリスト。max_tokens=1なので通常は要素が1つ。\n",
    "            # logprobs_info.content[0].top_logprobs が上位候補リスト。\n",
    "            # top_logprobs_list の各要素は TopLogprob オブジェクトであることに注意\n",
    "            if not logprobs_info or not logprobs_info.content or not logprobs_info.content[0].top_logprobs:\n",
    "                print(f\"  警告: APIレスポンスに十分な logprobs 情報が含まれていませんでした (プロンプト: '{prompt_text}')。\")\n",
    "                 # logprob 情報がなければ計算不可\n",
    "                return float('inf')\n",
    "\n",
    "\n",
    "            top_logprobs_list = logprobs_info.content[0].top_logprobs\n",
    "\n",
    "            # 上位候補リストから、対象トークンの logprob を探す\n",
    "            found_logprob = None\n",
    "            # APIレスポンスのトークンテキストと、tiktokenでデコードしたトークンテキストを比較\n",
    "            # repr() を使うとスペースや改行などの非表示文字を含めて比較できるためより安全\n",
    "            target_token_repr = repr(target_token_text)\n",
    "\n",
    "            for token_info in top_logprobs_list:\n",
    "                 # ここを修正: ドット記法 (.) で属性にアクセスする\n",
    "                 if repr(token_info.token) == target_token_repr:\n",
    "                     found_logprob = token_info.logprob # ここを修正\n",
    "                     break # 見つかったらループを抜ける\n",
    "\n",
    "\n",
    "            # 対象トークンの logprob が上位K個の中に見つかったか確認\n",
    "            if found_logprob is not None:\n",
    "                total_logprob += found_logprob\n",
    "                num_terms += 1\n",
    "                # print(f\"    Found '{target_token_text}' ({target_token_repr}): {found_logprob}\") # デバッグ用\n",
    "            else:\n",
    "                # 対象トークンが上位K個に含まれていない場合、その確率は非常に低い\n",
    "                # ここでは警告を表示し、非常に小さい確率（大きい負のlogprob）を代用する\n",
    "                fallback_logprob = -20.0 # 代用する大きな負のlogprob\n",
    "                total_logprob += fallback_logprob\n",
    "                num_terms += 1\n",
    "                print(f\"  警告: 対象トークン '{target_token_text}' ({target_token_repr}) が上位 {actual_top_k} 候補に見つかりませんでした (プロンプト: '{prompt_text}')。代用logprob ({fallback_logprob}) を使用します。\")\n",
    "                # 見つからなかった時点で計算不可とするなら以下のコメントを解除\n",
    "                # return float('inf')\n",
    "\n",
    "\n",
    "        # パープレキシティの計算\n",
    "        # Perplexity = exp(- (1/N) * Sum(log P))\n",
    "        # ここで N は合計したlogprobの数 (num_terms)\n",
    "        if num_terms == 0:\n",
    "            print(\"  エラー: logprobを計算できたトークンがありません。\")\n",
    "            return float('inf')\n",
    "\n",
    "        average_logprob = total_logprob / num_terms\n",
    "        perplexity = math.exp(-average_logprob)\n",
    "\n",
    "        return perplexity\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  致命的なエラーが発生しました: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "\n",
    "# --- 主処理 ---\n",
    "\n",
    "# パープレキシティを測定する文のリスト\n",
    "sentences_to_test = [\n",
    "    \"The movie was full of surprises\",       # 文法的にも意味的にも自然\n",
    "    \"The movies were full of surprises\",     # 主語・動詞が複数形で一致、自然\n",
    "    \"The movie were full of surprises\",      # 主語が単数、動詞が複数形で不一致 (文法ミス)\n",
    "    \"The movies was full of surprises\",      # 主語が複数、動詞が単数形で不一致 (文法ミス)\n",
    "    \"Surprises full of was movie The\",       # 単語順序が不自然 (文法ミス)\n",
    "    \"This is a very common sentence\",        # 別の自然な文\n",
    "    \"This very is a common sentence\",        # 単語順序が不自然 (文法ミス)\n",
    "    \"The quick brown fox jumps over the lazy dog\", # より長い標準的な文\n",
    "]\n",
    "\n",
    "model_name = \"gpt-4o\" # あなたのAzure OpenAIでデプロイしたモデル名を指定\n",
    "# APIの制限に合わせて top_k_for_logprobs を 20 に修正\n",
    "top_k_for_logprobs = 20\n",
    "api_delay_seconds = 0.01 # API呼び出し間の短い遅延 (推奨)\n",
    "\n",
    "print(f\"=== 課題 ===\")\n",
    "print(f\"与えられた文に対するパープレキシティを測定し、比較する。\")\n",
    "print(f\"モデル: {model_name}\")\n",
    "print(f\"logprob取得のための上位K (API制限): {top_k_for_logprobs}\")\n",
    "print(f\"API遅延: {api_delay_seconds}秒\")\n",
    "print(\"============\")\n",
    "\n",
    "# クライアントが初期化されているか確認\n",
    "if client is None:\n",
    "    print(\"\\nエラー: Azure OpenAI クライアントが初期化されていません。パープレキシティ計算を実行できません。\")\n",
    "else:\n",
    "    print(\"\\n=== パープレキシティ測定結果 ===\")\n",
    "    # 各文に対してパープレキシティを計算し表示\n",
    "    for sentence in sentences_to_test:\n",
    "        # calculate_perplexity 関数内でクライアント初期化の成功をチェック\n",
    "        perplexity_value = calculate_perplexity(client, model_name, sentence, top_k_for_logprobs, api_delay_seconds)\n",
    "\n",
    "        if perplexity_value == float('inf'):\n",
    "            print(f\"文: '{sentence}'\")\n",
    "            print(f\"パープレキシティ: 計算不可\") # エラーメッセージは関数内で出力済み\n",
    "        else:\n",
    "            print(f\"文: '{sentence}'\")\n",
    "            print(f\"パープレキシティ: {perplexity_value:.4f}\") # 小数点以下4桁で表示\n",
    "        print(\"-\" * 30) # 区切り線"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-7fB-n9suYg"
   },
   "source": [
    "## 94. チャットテンプレート\n",
    "\n",
    "\"What do you call a sweet eaten after dinner?\"という問いかけに対する応答を生成するため、チャットテンプレートを適用し、言語モデルに与えるべきプロンプトを作成せよ。また、そのプロンプトに対する応答を生成し、表示せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "PT-bk0XWIZ2E",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 95. マルチターンのチャット\n",
    "\n",
    "問題94で生成された応答に対して、追加で\"Please give me the plural form of the word with its spelling in reverse order.\"と問いかけたときの応答を生成・表示せよ。また、その時に言語モデルに与えるプロンプトを確認せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "qH0YortL0afd",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 96. プロンプトによる感情分析\n",
    "\n",
    "事前学習済み言語モデルで感情分析を行いたい。テキストを含むプロンプトを事前学習済み言語モデルに与え、（ファインチューニングは行わずに）テキストのポジネガを予測するという戦略で、[SST-2](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip)の開発データにおける正解率を測定せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "giA6FivrKaSf",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 97. 埋め込みに基づく感情分析\n",
    "\n",
    "事前学習済み言語モデルでテキストをベクトルで表現（エンコード）し、そのベクトルにフィードフォワード層を通すことで極性ラベルを予測するモデルを学習せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "UnREZD3nTWUr",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 98. ファインチューニング\n",
    "\n",
    "問題96のプロンプトに対して、正解の感情ラベルをテキストの応答として返すように事前学習済みモデルをファインチューニングせよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "4f0St5Ce0l34",
    "tags": []
   },
   "source": [
    "## 99. 選好チューニング\n",
    "\n",
    "問題96のプロンプトに対して、正解の感情ラベルを含むテキストを望ましい応答、間違った感情ラベルを含むテキストを望ましくない応答として、事前学習済み言語モデルを選好チューニング (preference tuning) を実施せよ。選好チューニングのアルゴリズムとしては、近傍方策最適化 (PPO: Proximal Policy Optimization) や直接選好最適化 (DPO: Direct Preference Optimization) などが考えられる。\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a56790cc58c4155bb4fb62352fe6853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c4e978f772946f293451de4484720ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da96a5f6901649958e682be81f939149",
      "placeholder": "​",
      "style": "IPY_MODEL_3f9c4fcaa07b42a0971b99205dd05458",
      "value": " 1/1 [00:00&lt;00:00, 25.67it/s]"
     }
    },
    "0f1172658036407993eb46da17554501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd75431e52b54d9bb2fd7c06737c28f5",
      "placeholder": "​",
      "style": "IPY_MODEL_12c4ec93b2fc4b239b775d5b947b253f",
      "value": " 67349/0 [00:00&lt;00:00, 674165.72 examples/s]"
     }
    },
    "12c4ec93b2fc4b239b775d5b947b253f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1411c82bf2f3475a826a145fb9f89626": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "145b34f60df1429e8685bcc9b2f05be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c8a470363f246d692c48ab4a502c4c7",
      "max": 872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae5b03ae867f4ffba662a8888b319926",
      "value": 872
     }
    },
    "14c91ad60bc84fb0a9c6cc1eb9365425": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b91de93f8ec46c2ac153f40f50ae2e0",
      "placeholder": "​",
      "style": "IPY_MODEL_f4367d9584aa42e0b4249b33af0435d9",
      "value": "Generating train split: "
     }
    },
    "16763c09bfa34f03821316fe7c9902e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c57bd417124c4faa8652b13e826405db",
       "IPY_MODEL_3248b0100e614e2a89b0e2dc13be0ad5",
       "IPY_MODEL_936c040e05bc4b2aadd82245d0c2f3b3"
      ],
      "layout": "IPY_MODEL_a1aac38df0bd43bf9a48a55be029f499"
     }
    },
    "1860eb6e26ca45aeab8ab4ab41334a25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29245bfd86f0460ea2bfccaca75690a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e33f53fccce4875bbb245afe5b87cf3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5cbbe2769e024a92a5aa718d8f889d0f",
      "value": 1
     }
    },
    "2b91de93f8ec46c2ac153f40f50ae2e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3248b0100e614e2a89b0e2dc13be0ad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93d07d6d16da45b2a248ad37e51c3180",
      "max": 67349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a03ab49faf2a4027906a0e9f806bd2db",
      "value": 67349
     }
    },
    "3c41fe7af38f49f581ae359b5d970d23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f95aef5e2c74acd8ffbfad2543b2102",
      "placeholder": "​",
      "style": "IPY_MODEL_9a20391390dd4f96aaea37321b4dfb53",
      "value": " 872/0 [00:00&lt;00:00, 66375.69 examples/s]"
     }
    },
    "3f6a346c2abd42ea9fb5af9441376472": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_97484a182f634ec8a711d516fdeb0c63",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7453ed4be064ab586858e8dec61ffae",
      "value": 1
     }
    },
    "3f95aef5e2c74acd8ffbfad2543b2102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9c4fcaa07b42a0971b99205dd05458": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b8bf221e7974b65b4dde96219ce0f47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bc6646a088f4bd7b58b33ae1bbab1ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d1eef416f5944c2911154fb770d869f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54587b2141984fd495bf55ea6df0d1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d603aabb8b6443d2a66b94701858f523",
      "placeholder": "​",
      "style": "IPY_MODEL_1411c82bf2f3475a826a145fb9f89626",
      "value": "Generating dev split: "
     }
    },
    "5cbbe2769e024a92a5aa718d8f889d0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "64ebcabb9c26423f8cda28966d9bbedb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "678df530cc994774899eb213581f737b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c8a470363f246d692c48ab4a502c4c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75a29e01568b4272832f3e00dd92a707": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80837417e00b4fd3814524786898697c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81b067d9308141c786bc70f709681ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54587b2141984fd495bf55ea6df0d1a5",
       "IPY_MODEL_29245bfd86f0460ea2bfccaca75690a1",
       "IPY_MODEL_3c41fe7af38f49f581ae359b5d970d23"
      ],
      "layout": "IPY_MODEL_4bc6646a088f4bd7b58b33ae1bbab1ae"
     }
    },
    "8dec4107d6a44cdaae9020345e2c25a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e33f53fccce4875bbb245afe5b87cf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "936c040e05bc4b2aadd82245d0c2f3b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64ebcabb9c26423f8cda28966d9bbedb",
      "placeholder": "​",
      "style": "IPY_MODEL_678df530cc994774899eb213581f737b",
      "value": " 67349/67349 [00:03&lt;00:00, 20324.02 examples/s]"
     }
    },
    "93d07d6d16da45b2a248ad37e51c3180": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97484a182f634ec8a711d516fdeb0c63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9a20391390dd4f96aaea37321b4dfb53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a03ab49faf2a4027906a0e9f806bd2db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a1aac38df0bd43bf9a48a55be029f499": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3164d72e2d5431dbd7921b74290193a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3cd48beab0741b99a7885f89ebe1181": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8eb7b58bb3a4bfc9d4dad2bc0857dbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4da859c892b42cfa6c909e7dfe2df7d",
       "IPY_MODEL_df8979acad044b40bb55c3e00c418e05",
       "IPY_MODEL_0c4e978f772946f293451de4484720ed"
      ],
      "layout": "IPY_MODEL_b913e33aebe642cca6fa8a6ade682988"
     }
    },
    "ae5b03ae867f4ffba662a8888b319926": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b1763f6b7fc9430ab2f773279fdd954d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75a29e01568b4272832f3e00dd92a707",
      "placeholder": "​",
      "style": "IPY_MODEL_8dec4107d6a44cdaae9020345e2c25a4",
      "value": "Map: 100%"
     }
    },
    "b913e33aebe642cca6fa8a6ade682988": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd75431e52b54d9bb2fd7c06737c28f5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0929c9ec77a48df8a7fd3e2f4539a51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c57bd417124c4faa8652b13e826405db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1860eb6e26ca45aeab8ab4ab41334a25",
      "placeholder": "​",
      "style": "IPY_MODEL_4b8bf221e7974b65b4dde96219ce0f47",
      "value": "Map: 100%"
     }
    },
    "d5e5c6c318cc41c4ac40647e6d5a5106": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_14c91ad60bc84fb0a9c6cc1eb9365425",
       "IPY_MODEL_3f6a346c2abd42ea9fb5af9441376472",
       "IPY_MODEL_0f1172658036407993eb46da17554501"
      ],
      "layout": "IPY_MODEL_0a56790cc58c4155bb4fb62352fe6853"
     }
    },
    "d603aabb8b6443d2a66b94701858f523": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7453ed4be064ab586858e8dec61ffae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da96a5f6901649958e682be81f939149": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deee5780a392426096c2ff4f76aa1547": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "df8979acad044b40bb55c3e00c418e05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec97a156272345ba8d456c5f090d9412",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_deee5780a392426096c2ff4f76aa1547",
      "value": 1
     }
    },
    "e92b3187acda44e9b30051a9e410f43f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b1763f6b7fc9430ab2f773279fdd954d",
       "IPY_MODEL_145b34f60df1429e8685bcc9b2f05be2",
       "IPY_MODEL_fc589f87f65d4a3196cdd790bbdf7fa0"
      ],
      "layout": "IPY_MODEL_c0929c9ec77a48df8a7fd3e2f4539a51"
     }
    },
    "ec97a156272345ba8d456c5f090d9412": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4367d9584aa42e0b4249b33af0435d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4da859c892b42cfa6c909e7dfe2df7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d1eef416f5944c2911154fb770d869f",
      "placeholder": "​",
      "style": "IPY_MODEL_a3164d72e2d5431dbd7921b74290193a",
      "value": "100%"
     }
    },
    "fc589f87f65d4a3196cdd790bbdf7fa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3cd48beab0741b99a7885f89ebe1181",
      "placeholder": "​",
      "style": "IPY_MODEL_80837417e00b4fd3814524786898697c",
      "value": " 872/872 [00:00&lt;00:00, 9939.81 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
