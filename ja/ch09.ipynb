{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "1HhY1_KNjX_Y",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 第9章: 事前学習済み言語モデル（BERT型）\n",
    "\n",
    "本章では、BERT型の事前学習済みモデルを利用して、マスク単語の予測や文ベクトルの計算、評判分析器（ポジネガ分類器）の構築に取り組む。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyLKl_eo_80z"
   },
   "source": [
    "## 80. トークン化\n",
    "\n",
    "\"The movie was full of incomprehensibilities.\"という文をトークンに分解し、トークン列を表示せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トークナイザ 'bert-base-uncased' をロードしました。\n",
      "\n",
      "元のテキスト: \"The movie was full of incomprehensibilities.\"\n",
      "\n",
      "トークン化された列:\n",
      "['the', 'movie', 'was', 'full', 'of', 'inc', '##omp', '##re', '##hen', '##si', '##bilities', '.']\n",
      "------------------------------\n",
      "（参考情報）\n",
      "\n",
      "encode() によるトークンID (特殊トークン含む):\n",
      "[101, 1996, 3185, 2001, 2440, 1997, 4297, 25377, 2890, 10222, 5332, 14680, 1012, 102]\n",
      "\n",
      "上記IDをトークン文字列に戻したもの (特殊トークン含む):\n",
      "['[CLS]', 'the', 'movie', 'was', 'full', 'of', 'inc', '##omp', '##re', '##hen', '##si', '##bilities', '.', '[SEP]']\n",
      "\n",
      "__call__() によるモデル入力形式 (PyTorchテンソル):\n",
      "  Input IDs: tensor([[  101,  1996,  3185,  2001,  2440,  1997,  4297, 25377,  2890, 10222,\n",
      "          5332, 14680,  1012,   102]])\n",
      "  Token Type IDs: tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "  Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face Transformers ライブラリのインストール (まだの場合、Jupyter Notebookのセルで先頭に!をつけて実行)\n",
    "# !pip install transformers\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. トークナイザのロード\n",
    "# 一般的な英語BERTモデルである 'bert-base-uncased' を例として使用します。\n",
    "# このモデルは、テキストを小文字化してからトークン化します。\n",
    "# 他のモデル名 (例: 'bert-base-cased', 'bert-large-uncased') も指定可能です。\n",
    "tokenizer_name = \"bert-base-uncased\" \n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    print(f\"トークナイザ '{tokenizer_name}' をロードしました。\")\n",
    "except Exception as e:\n",
    "    print(f\"トークナイザ '{tokenizer_name}' のロード中にエラーが発生しました: {e}\")\n",
    "    print(\"指定したモデル名が正しいか、インターネット接続があるか確認してください。\")\n",
    "    print(\"Hugging Face Hub (https://huggingface.co/models) でモデル名を確認できます。\")\n",
    "    tokenizer = None # エラーの場合はtokenizerをNoneに設定\n",
    "\n",
    "if tokenizer:\n",
    "    # 2. トークン化するテキスト\n",
    "    text_to_tokenize = \"The movie was full of incomprehensibilities.\"\n",
    "    print(f\"\\n元のテキスト: \\\"{text_to_tokenize}\\\"\")\n",
    "\n",
    "    # 3. テキストのトークン化\n",
    "    # tokenize() メソッドは、テキストをトークンの文字列リストに分割します。\n",
    "    tokens = tokenizer.tokenize(text_to_tokenize)\n",
    "    \n",
    "    # 4. トークン列の表示\n",
    "    print(\"\\nトークン化された列:\")\n",
    "    print(tokens)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"（参考情報）\")\n",
    "    # 参考: トークナイザの encode() メソッドによる出力 (トークンIDのリスト)\n",
    "    # add_special_tokens=True にすると、[CLS] や [SEP] といった特殊トークンも自動的に付与されます。\n",
    "    # (BERTが文の入力を受け付ける際の標準的な形式)\n",
    "    token_ids_with_special_tokens = tokenizer.encode(text_to_tokenize, add_special_tokens=True)\n",
    "    print(f\"\\nencode() によるトークンID (特殊トークン含む):\")\n",
    "    print(token_ids_with_special_tokens)\n",
    "    \n",
    "    # 参考: 上記のトークンIDを再度トークン文字列に変換\n",
    "    decoded_tokens_with_special = tokenizer.convert_ids_to_tokens(token_ids_with_special_tokens)\n",
    "    print(f\"\\n上記IDをトークン文字列に戻したもの (特殊トークン含む):\")\n",
    "    print(decoded_tokens_with_special)\n",
    "\n",
    "    # 参考: トークナイザの __call__() メソッド (推奨される使い方)\n",
    "    # PyTorchテンソル形式で、モデル入力に必要な情報をまとめて取得できます。\n",
    "    inputs = tokenizer(text_to_tokenize, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    print(\"\\n__call__() によるモデル入力形式 (PyTorchテンソル):\")\n",
    "    print(f\"  Input IDs: {inputs['input_ids']}\")\n",
    "    if 'token_type_ids' in inputs: # モデルによっては token_type_ids がない場合もある\n",
    "        print(f\"  Token Type IDs: {inputs['token_type_ids']}\")\n",
    "    print(f\"  Attention Mask: {inputs['attention_mask']}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "else:\n",
    "    print(\"\\nトークナイザがロードされなかったため、処理を実行できませんでした。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Lbx12UDACt6"
   },
   "source": [
    "## 81. マスクの予測\n",
    "\n",
    "\"The movie was full of [MASK].\"の\"[MASK]\"を埋めるのに最も適切なトークンを求めよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トークナイザ 'bert-base-uncased' とモデル 'bert-base-uncased' をロードしました。\n",
      "\n",
      "入力テキスト: \"The movie was full of [MASK].\"\n",
      "[MASK] トークンの位置 (インデックス): 6\n",
      "\n",
      "[MASK] を埋めるのに最も適切なトークン: \"fun\"\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face Transformers ライブラリのインストール (まだの場合)\n",
    "# !pip install transformers\n",
    "# !pip install torch # PyTorchも必要\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# 1. トークナイザとモデルのロード\n",
    "# 問題80で使用したのと同じモデル名を指定するのが一般的\n",
    "tokenizer_name_mlm = \"bert-base-uncased\"\n",
    "model_name_mlm = \"bert-base-uncased\" \n",
    "\n",
    "try:\n",
    "    tokenizer_mlm = AutoTokenizer.from_pretrained(tokenizer_name_mlm)\n",
    "    model_mlm = AutoModelForMaskedLM.from_pretrained(model_name_mlm)\n",
    "    print(f\"トークナイザ '{tokenizer_name_mlm}' とモデル '{model_name_mlm}' をロードしました。\")\n",
    "    \n",
    "    # モデルを評価モードに設定 (推論のみ行うため)\n",
    "    model_mlm.eval()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"トークナイザまたはモデルのロード中にエラーが発生しました: {e}\")\n",
    "    tokenizer_mlm = None\n",
    "    model_mlm = None\n",
    "\n",
    "if tokenizer_mlm and model_mlm:\n",
    "    # 2. 入力テキストの準備\n",
    "    text_with_mask = \"The movie was full of [MASK].\"\n",
    "    print(f\"\\n入力テキスト: \\\"{text_with_mask}\\\"\")\n",
    "\n",
    "    # 3. テキストのトークン化とマスク位置の特定\n",
    "    # モデル入力形式で取得 (PyTorchテンソル)\n",
    "    inputs = tokenizer_mlm(text_with_mask, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # [MASK] トークンのIDを取得\n",
    "    mask_token_id = tokenizer_mlm.mask_token_id\n",
    "    \n",
    "    # input_ids の中で [MASK] トークンID がある位置(インデックス)を見つける\n",
    "    # バッチサイズ1を想定\n",
    "    mask_token_indices = torch.where(input_ids == mask_token_id)[1] # [1]で列インデックスを取得\n",
    "\n",
    "    if len(mask_token_indices) == 0:\n",
    "        print(\"エラー: 入力テキストに [MASK] トークンが見つかりません。\")\n",
    "    else:\n",
    "        mask_token_index = mask_token_indices[0] # 最初のマスク位置を使用\n",
    "        print(f\"[MASK] トークンの位置 (インデックス): {mask_token_index.item()}\")\n",
    "\n",
    "        # 4. モデルによる予測 (勾配計算は不要なので torch.no_grad() を使用)\n",
    "        with torch.no_grad():\n",
    "            outputs = model_mlm(**inputs) # キーワード引数として渡す\n",
    "            predictions = outputs.logits\n",
    "            # predictions の形状: (バッチサイズ, シーケンス長, 語彙サイズ)\n",
    "        \n",
    "        # 5. 最も適切なトークンの特定\n",
    "        # [MASK] トークンの位置における予測 logits を取得\n",
    "        mask_token_logits = predictions[0, mask_token_index, :] # バッチサイズ1を仮定\n",
    "        \n",
    "        # 最もスコアが高いトークンのIDを予測\n",
    "        predicted_token_id = torch.argmax(mask_token_logits).item()\n",
    "        \n",
    "        # 予測されたトークンIDを実際のトークン文字列に変換\n",
    "        predicted_token = tokenizer_mlm.convert_ids_to_tokens([predicted_token_id])[0]\n",
    "        \n",
    "        print(f\"\\n[MASK] を埋めるのに最も適切なトークン: \\\"{predicted_token}\\\"\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nトークナイザまたはモデルがロードされなかったため、処理を実行できませんでした。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F39DStXDk3OG"
   },
   "source": [
    "## 82. マスクのtop-k予測\n",
    "\n",
    "\"The movie was full of [MASK].\"の\"[MASK]\"に埋めるのに適切なトークン上位10個と、その確率（尤度）を求めよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題81でロード済みのトークナイザ 'bert-base-uncased' とモデルを使用します。\n",
      "\n",
      "入力テキスト: \"The movie was full of [MASK].\"\n",
      "[MASK] トークンの位置 (インデックス): 6\n",
      "\n",
      "[MASK] を埋めるのに適切なトークン上位10個と、その確率:\n",
      "  1. トークン: \"fun\", 確率: 0.1071\n",
      "  2. トークン: \"surprises\", 確率: 0.0663\n",
      "  3. トークン: \"drama\", 確率: 0.0447\n",
      "  4. トークン: \"stars\", 確率: 0.0272\n",
      "  5. トークン: \"laughs\", 確率: 0.0254\n",
      "  6. トークン: \"action\", 確率: 0.0195\n",
      "  7. トークン: \"excitement\", 確率: 0.0190\n",
      "  8. トークン: \"people\", 確率: 0.0183\n",
      "  9. トークン: \"tension\", 確率: 0.0150\n",
      "  10. トークン: \"music\", 確率: 0.0146\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F # ソフトマックス関数を使用するため\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# 1. トークナイザとモデルのロード (問題81でロード済みであれば再利用)\n",
    "# tokenizer_name_mlm = \"bert-base-uncased\" # 問題81と同じ\n",
    "# model_name_mlm = \"bert-base-uncased\"   # 問題81と同じ\n",
    "\n",
    "# tokenizer_mlm と model_mlm が問題81から引き継がれているか確認\n",
    "if 'tokenizer_mlm' not in locals() or 'model_mlm' not in locals() or \\\n",
    "   tokenizer_mlm is None or model_mlm is None:\n",
    "    print(\"エラー: 'tokenizer_mlm' または 'model_mlm' が定義されていません。\")\n",
    "    print(\"問題81を先に実行して、トークナイザとモデルをロードしてください。\")\n",
    "    # 処理を中断するための措置\n",
    "    raise NameError(\"Tokenizer or Model not loaded from Problem 81.\")\n",
    "else:\n",
    "    print(f\"問題81でロード済みのトークナイザ '{tokenizer_mlm.name_or_path}' とモデルを使用します。\")\n",
    "    model_mlm.eval() # 念のため評価モードに\n",
    "\n",
    "# 2. 入力テキストの準備\n",
    "text_with_mask_top_k = \"The movie was full of [MASK].\"\n",
    "print(f\"\\n入力テキスト: \\\"{text_with_mask_top_k}\\\"\")\n",
    "\n",
    "# 3. テキストのトークン化とマスク位置の特定\n",
    "inputs_top_k = tokenizer_mlm(text_with_mask_top_k, return_tensors=\"pt\", add_special_tokens=True)\n",
    "input_ids_top_k = inputs_top_k[\"input_ids\"]\n",
    "mask_token_id_top_k = tokenizer_mlm.mask_token_id\n",
    "mask_token_indices_top_k = torch.where(input_ids_top_k == mask_token_id_top_k)[1]\n",
    "\n",
    "if len(mask_token_indices_top_k) == 0:\n",
    "    print(\"エラー: 入力テキストに [MASK] トークンが見つかりません。\")\n",
    "else:\n",
    "    mask_token_index_top_k = mask_token_indices_top_k[0]\n",
    "    print(f\"[MASK] トークンの位置 (インデックス): {mask_token_index_top_k.item()}\")\n",
    "\n",
    "    # 4. モデルによる予測とスコア取得 (勾配計算は不要)\n",
    "    with torch.no_grad():\n",
    "        outputs_top_k = model_mlm(**inputs_top_k)\n",
    "        predictions_top_k = outputs_top_k.logits\n",
    "    \n",
    "    # [MASK] トークンの位置における予測 logits を取得\n",
    "    mask_token_logits_top_k = predictions_top_k[0, mask_token_index_top_k, :]\n",
    "    \n",
    "    # 5. 上位k個のトークンとその確率の特定\n",
    "    top_k = 10\n",
    "    \n",
    "    # ロジットを確率に変換 (ソフトマックス)\n",
    "    mask_token_probs = F.softmax(mask_token_logits_top_k, dim=-1)\n",
    "    \n",
    "    # 確率が高い上位k個のトークンの確率値とインデックス(ID)を取得\n",
    "    top_k_probs, top_k_indices = torch.topk(mask_token_probs, top_k)\n",
    "    \n",
    "    # 予測された上位k個のトークンIDを実際のトークン文字列に変換\n",
    "    top_k_tokens = tokenizer_mlm.convert_ids_to_tokens(top_k_indices)\n",
    "    \n",
    "    print(f\"\\n[MASK] を埋めるのに適切なトークン上位{top_k}個と、その確率:\")\n",
    "    for i in range(top_k):\n",
    "        print(f\"  {i+1}. トークン: \\\"{top_k_tokens[i]}\\\", 確率: {top_k_probs[i].item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zr6VVYiRPzk"
   },
   "source": [
    "## 83. CLSトークンによる文ベクトル\n",
    "\n",
    "以下の文の全ての組み合わせに対して、最終層の[CLS]トークンの埋め込みベクトルを用いてコサイン類似度を求めよ。\n",
    "\n",
    "- \"The movie was full of fun.\"\n",
    "- \"The movie was full of excitement.\"\n",
    "- \"The movie was full of crap.\"\n",
    "- \"The movie was full of rubbish.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "トークナイザ 'bert-base-uncased' とモデル 'bert-base-uncased' をロードしました。\n",
      "\n",
      "各文の[CLS]トークンベクトルを抽出します...\n",
      "  文: \"The movie was full of fun.\" -> CLSベクトル抽出完了 (形状: torch.Size([768]))\n",
      "  文: \"The movie was full of excitement.\" -> CLSベクトル抽出完了 (形状: torch.Size([768]))\n",
      "  文: \"The movie was full of crap.\" -> CLSベクトル抽出完了 (形状: torch.Size([768]))\n",
      "  文: \"The movie was full of rubbish.\" -> CLSベクトル抽出完了 (形状: torch.Size([768]))\n",
      "\n",
      "文ペア間のコサイン類似度:\n",
      "  文1: \"The movie was full of fun.\"\n",
      "  文2: \"The movie was full of excitement.\"\n",
      "  コサイン類似度: 0.9881\n",
      "\n",
      "  文1: \"The movie was full of fun.\"\n",
      "  文2: \"The movie was full of crap.\"\n",
      "  コサイン類似度: 0.9558\n",
      "\n",
      "  文1: \"The movie was full of fun.\"\n",
      "  文2: \"The movie was full of rubbish.\"\n",
      "  コサイン類似度: 0.9475\n",
      "\n",
      "  文1: \"The movie was full of excitement.\"\n",
      "  文2: \"The movie was full of crap.\"\n",
      "  コサイン類似度: 0.9541\n",
      "\n",
      "  文1: \"The movie was full of excitement.\"\n",
      "  文2: \"The movie was full of rubbish.\"\n",
      "  コサイン類似度: 0.9487\n",
      "\n",
      "  文1: \"The movie was full of crap.\"\n",
      "  文2: \"The movie was full of rubbish.\"\n",
      "  コサイン類似度: 0.9807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F # コサイン類似度の計算用\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from itertools import combinations # 文のペア作成用\n",
    "\n",
    "# 1. トークナイザとモデルのロード\n",
    "# 問題80-82と同じトークナイザ、ただしモデルは AutoModel を使用\n",
    "tokenizer_name_cls = \"bert-base-uncased\" \n",
    "model_name_cls = \"bert-base-uncased\"     # 事前学習済みBERTモデル\n",
    "\n",
    "try:\n",
    "    tokenizer_cls = AutoTokenizer.from_pretrained(tokenizer_name_cls)\n",
    "    # CLSトークンベクトルを取得するため、AutoModelForMaskedLMではなくAutoModelを使用\n",
    "    model_cls = AutoModel.from_pretrained(model_name_cls)\n",
    "    print(f\"トークナイザ '{tokenizer_name_cls}' とモデル '{model_name_cls}' をロードしました。\")\n",
    "    \n",
    "    # モデルを評価モードに設定\n",
    "    model_cls.eval()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"トークナイザまたはモデルのロード中にエラーが発生しました: {e}\")\n",
    "    tokenizer_cls = None\n",
    "    model_cls = None\n",
    "\n",
    "def get_cls_vector(text, tokenizer, model):\n",
    "    \"\"\"テキストからBERTの最終層の[CLS]トークンベクトルを取得する関数\"\"\"\n",
    "    if not tokenizer or not model:\n",
    "        return None\n",
    "        \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True, truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # last_hidden_state の形状: (バッチサイズ, シーケンス長, 隠れ層次元数)\n",
    "        # [CLS] トークンはシーケンスの最初のトークン (インデックス0)\n",
    "        cls_vector = outputs.last_hidden_state[:, 0, :] # バッチ内の全事例のCLSトークンを取得\n",
    "        # 今回は1文ずつ処理するので、バッチサイズは1\n",
    "        return cls_vector[0] # (隠れ層次元数) の形状のテンソルを返す\n",
    "\n",
    "if tokenizer_cls and model_cls:\n",
    "    # 3. 対象の文リスト\n",
    "    sentences = [\n",
    "        \"The movie was full of fun.\",\n",
    "        \"The movie was full of excitement.\",\n",
    "        \"The movie was full of crap.\",\n",
    "        \"The movie was full of rubbish.\"\n",
    "    ]\n",
    "\n",
    "    print(\"\\n各文の[CLS]トークンベクトルを抽出します...\")\n",
    "    sentence_vectors = {}\n",
    "    for sentence in sentences:\n",
    "        cls_vec = get_cls_vector(sentence, tokenizer_cls, model_cls)\n",
    "        if cls_vec is not None:\n",
    "            sentence_vectors[sentence] = cls_vec\n",
    "            print(f\"  文: \\\"{sentence}\\\" -> CLSベクトル抽出完了 (形状: {cls_vec.shape})\")\n",
    "        else:\n",
    "            print(f\"  文: \\\"{sentence}\\\" -> CLSベクトル抽出失敗\")\n",
    "\n",
    "    # 4. 各文ペアに対するコサイン類似度の計算\n",
    "    print(\"\\n文ペア間のコサイン類似度:\")\n",
    "    # sentences リストのインデックスではなく、sentence_vectors のキー (文自体) を使う\n",
    "    # これにより、ベクトル抽出に失敗した文は自動的に除外される\n",
    "    valid_sentences = list(sentence_vectors.keys())\n",
    "\n",
    "    for sent1, sent2 in combinations(valid_sentences, 2): # 全てのユニークなペアを作成\n",
    "        if sent1 in sentence_vectors and sent2 in sentence_vectors:\n",
    "            vec1 = sentence_vectors[sent1].unsqueeze(0) # (1, hidden_dim) に形状変更\n",
    "            vec2 = sentence_vectors[sent2].unsqueeze(0) # (1, hidden_dim) に形状変更\n",
    "            \n",
    "            # コサイン類似度を計算 (torch.nn.functional.cosine_similarity)\n",
    "            # F.cosine_similarity は (N, D) と (N, D) を比較し、(N) を返すので、\n",
    "            # ここでは (1, D) と (1, D) から (1) のテンソルが得られる\n",
    "            similarity = F.cosine_similarity(vec1, vec2, dim=1) # dim=1でベクトル間で計算\n",
    "            \n",
    "            print(f\"  文1: \\\"{sent1}\\\"\")\n",
    "            print(f\"  文2: \\\"{sent2}\\\"\")\n",
    "            print(f\"  コサイン類似度: {similarity.item():.4f}\\n\")\n",
    "else:\n",
    "    print(\"\\nトークナイザまたはモデルがロードされなかったため、処理を実行できませんでした。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oqo5Ufzkyc89"
   },
   "source": [
    "## 84. 平均による文ベクトル\n",
    "\n",
    "以下の文の全ての組み合わせに対して、最終層の埋め込みベクトルの平均を用いてコサイン類似度を求めよ。\n",
    "\n",
    "- \"The movie was full of fun.\"\n",
    "- \"The movie was full of excitement.\"\n",
    "- \"The movie was full of crap.\"\n",
    "- \"The movie was full of rubbish.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題83でロード済みのトークナイザ 'bert-base-uncased' とモデルを使用します。\n",
      "\n",
      "各文の最終層平均ベクトルを抽出します...\n",
      "  文: \"The movie was full of fun.\" -> 平均ベクトル抽出完了 (形状: torch.Size([768]))\n",
      "  文: \"The movie was full of excitement.\" -> 平均ベクトル抽出完了 (形状: torch.Size([768]))\n",
      "  文: \"The movie was full of crap.\" -> 平均ベクトル抽出完了 (形状: torch.Size([768]))\n",
      "  文: \"The movie was full of rubbish.\" -> 平均ベクトル抽出完了 (形状: torch.Size([768]))\n",
      "\n",
      "文ペア間のコサイン類似度 (平均ベクトル使用):\n",
      "  文1: \"The movie was full of fun.\"\n",
      "  文2: \"The movie was full of excitement.\"\n",
      "  コサイン類似度: 0.9568\n",
      "\n",
      "  文1: \"The movie was full of fun.\"\n",
      "  文2: \"The movie was full of crap.\"\n",
      "  コサイン類似度: 0.8490\n",
      "\n",
      "  文1: \"The movie was full of fun.\"\n",
      "  文2: \"The movie was full of rubbish.\"\n",
      "  コサイン類似度: 0.8169\n",
      "\n",
      "  文1: \"The movie was full of excitement.\"\n",
      "  文2: \"The movie was full of crap.\"\n",
      "  コサイン類似度: 0.8352\n",
      "\n",
      "  文1: \"The movie was full of excitement.\"\n",
      "  文2: \"The movie was full of rubbish.\"\n",
      "  コサイン類似度: 0.7938\n",
      "\n",
      "  文1: \"The movie was full of crap.\"\n",
      "  文2: \"The movie was full of rubbish.\"\n",
      "  コサイン類似度: 0.9226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from itertools import combinations\n",
    "\n",
    "# 1. トークナイザとモデルのロード (問題83でロード済みであれば再利用)\n",
    "# tokenizer_name_avg = \"bert-base-uncased\" \n",
    "# model_name_avg = \"bert-base-uncased\"\n",
    "\n",
    "# tokenizer_cls と model_cls が問題83から引き継がれているか確認\n",
    "if 'tokenizer_cls' not in locals() or 'model_cls' not in locals() or \\\n",
    "   tokenizer_cls is None or model_cls is None:\n",
    "    print(\"エラー: 'tokenizer_cls' または 'model_cls' が定義されていません。\")\n",
    "    print(\"問題83を先に実行して、トークナイザとモデルをロードしてください。\")\n",
    "    # 処理を中断するための措置\n",
    "    raise NameError(\"Tokenizer or Model not loaded from Problem 83.\")\n",
    "else:\n",
    "    print(f\"問題83でロード済みのトークナイザ '{tokenizer_cls.name_or_path}' とモデルを使用します。\")\n",
    "    # 変数名をこの問題用に変えるか、そのまま tokenizer_cls, model_cls を使用\n",
    "    tokenizer_avg = tokenizer_cls\n",
    "    model_avg = model_cls\n",
    "    model_avg.eval() # 念のため評価モードに\n",
    "\n",
    "def get_mean_pooling_vector(text, tokenizer, model):\n",
    "    \"\"\"テキストからBERTの最終層の全トークンベクトルの平均 (attention_mask利用) を取得する関数\"\"\"\n",
    "    if not tokenizer or not model:\n",
    "        return None\n",
    "        \n",
    "    # padding=True, truncation=True を指定して、バッチ処理に対応できるようにし、\n",
    "    # かつ長すぎるシーケンスを切り詰める\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True, \n",
    "                       padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    attention_mask = inputs['attention_mask'] # (バッチサイズ, シーケンス長)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state # (バッチサイズ, シーケンス長, 隠れ層次元数)\n",
    "    \n",
    "    # attention_mask を使って、パディングされていないトークンのベクトルのみを対象に平均を取る\n",
    "    # [CLS] や [SEP] も含めて平均を取るか、除外するかは設計による。\n",
    "    # ここでは、attention_maskが1の部分（非パディング、特殊トークン含む）の平均を取る。\n",
    "    # より厳密に [CLS], [SEP] を除きたい場合は、input_idsを調べてマスクを調整する。\n",
    "    \n",
    "    # attention_maskを (バッチサイズ, シーケンス長, 1) に拡張してブロードキャスト可能にする\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_states.size()).float()\n",
    "    \n",
    "    # マスクされた部分のベクトルを0にする (実際にはsumを取るので影響は限定的だが、明示的)\n",
    "    sum_embeddings = torch.sum(last_hidden_states * input_mask_expanded, 1) # シーケンス長次元で合計\n",
    "    \n",
    "    # マスクされた部分を除いた実際のトークン数をカウント (各事例ごと)\n",
    "    sum_mask = input_mask_expanded.sum(1) # (バッチサイズ, 1)\n",
    "    sum_mask = torch.clamp(sum_mask, min=1e-9) # ゼロ除算を避ける\n",
    "    \n",
    "    mean_pooled_vector = sum_embeddings / sum_mask\n",
    "    \n",
    "    # 今回は1文ずつ処理するので、バッチサイズは1\n",
    "    return mean_pooled_vector[0] # (隠れ層次元数) の形状のテンソルを返す\n",
    "\n",
    "if tokenizer_avg and model_avg:\n",
    "    # 3. 対象の文リスト (問題83と同じ)\n",
    "    sentences_avg = [\n",
    "        \"The movie was full of fun.\",\n",
    "        \"The movie was full of excitement.\",\n",
    "        \"The movie was full of crap.\",\n",
    "        \"The movie was full of rubbish.\"\n",
    "    ]\n",
    "\n",
    "    print(\"\\n各文の最終層平均ベクトルを抽出します...\")\n",
    "    sentence_vectors_avg = {}\n",
    "    for sentence in sentences_avg:\n",
    "        mean_vec = get_mean_pooling_vector(sentence, tokenizer_avg, model_avg)\n",
    "        if mean_vec is not None:\n",
    "            sentence_vectors_avg[sentence] = mean_vec\n",
    "            print(f\"  文: \\\"{sentence}\\\" -> 平均ベクトル抽出完了 (形状: {mean_vec.shape})\")\n",
    "        else:\n",
    "            print(f\"  文: \\\"{sentence}\\\" -> 平均ベクトル抽出失敗\")\n",
    "\n",
    "    # 4. 各文ペアに対するコサイン類似度の計算\n",
    "    print(\"\\n文ペア間のコサイン類似度 (平均ベクトル使用):\")\n",
    "    valid_sentences_avg = list(sentence_vectors_avg.keys())\n",
    "\n",
    "    for sent1, sent2 in combinations(valid_sentences_avg, 2):\n",
    "        if sent1 in sentence_vectors_avg and sent2 in sentence_vectors_avg:\n",
    "            vec1 = sentence_vectors_avg[sent1].unsqueeze(0)\n",
    "            vec2 = sentence_vectors_avg[sent2].unsqueeze(0)\n",
    "            \n",
    "            similarity = F.cosine_similarity(vec1, vec2, dim=1)\n",
    "            \n",
    "            print(f\"  文1: \\\"{sent1}\\\"\")\n",
    "            print(f\"  文2: \\\"{sent2}\\\"\")\n",
    "            print(f\"  コサイン類似度: {similarity.item():.4f}\\n\")\n",
    "else:\n",
    "    print(\"\\nトークナイザまたはモデルがロードされなかったため、処理を実行できませんでした。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s934DWT_1kFm"
   },
   "source": [
    "## 85. データセットの準備\n",
    "\n",
    "[General Language Understanding Evaluation (GLUE)](https://gluebenchmark.com/) ベンチマークで配布されている[Stanford Sentiment Treebank (SST)](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip) から訓練セット（train.tsv）と開発セット（dev.tsv）のテキストと極性ラベルと読み込み、さらに全てのテキストはトークン列に変換せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "問題83/84でロード済みのトークナイザ 'bert-base-uncased' を使用します。\n",
      "\n",
      "--- 訓練データ (train.tsv) ---\n",
      "元の事例数: 67349\n",
      "訓練データのテキストをトークン化しています (max_length=128)...\n",
      "訓練データの処理完了。\n",
      "  input_ids の形状: torch.Size([67349, 66])\n",
      "  attention_mask の形状: torch.Size([67349, 66])\n",
      "  labels の形状: torch.Size([67349])\n",
      "\n",
      "--- 開発データ (dev.tsv) ---\n",
      "元の事例数: 872\n",
      "開発データのテキストをトークン化しています (max_length=128)...\n",
      "開発データの処理完了。\n",
      "  input_ids の形状: torch.Size([872, 55])\n",
      "  attention_mask の形状: torch.Size([872, 55])\n",
      "  labels の形状: torch.Size([872])\n",
      "\n",
      "訓練データの最初の事例（トークンIDとデコード結果）:\n",
      "  Input IDs: [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Decoded Text: hide new secretions from the parental units\n",
      "  Original Text (from df): hide new secretions from the parental units \n",
      "  Label: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "# requests と zipfile, io は問題60でダウンロード・展開が済んでいれば不要な場合もある\n",
    "\n",
    "# --- 前提となる変数 (問題80から) ---\n",
    "# tokenizer_name = \"bert-base-uncased\" # 問題80で使用したトークナイザ名\n",
    "# tokenizer: 問題80でロードした AutoTokenizer のインスタンス\n",
    "\n",
    "# トークナイザがロードされているか確認\n",
    "if 'tokenizer_cls' in locals() and tokenizer_cls is not None: # 問題83/84のものを流用\n",
    "    tokenizer = tokenizer_cls\n",
    "    print(f\"問題83/84でロード済みのトークナイザ '{tokenizer.name_or_path}' を使用します。\")\n",
    "elif 'tokenizer_mlm' in locals() and tokenizer_mlm is not None: # 問題81/82のものを流用\n",
    "    tokenizer = tokenizer_mlm\n",
    "    print(f\"問題81/82でロード済みのトークナイザ '{tokenizer.name_or_path}' を使用します。\")\n",
    "elif 'tokenizer' in locals() and tokenizer is not None: # 問題80のものを流用\n",
    "    print(f\"問題80でロード済みのトークナイザ '{tokenizer.name_or_path}' を使用します。\")\n",
    "else:\n",
    "    print(\"エラー: BERTトークナイザがロードされていません。問題80を先に実行してください。\")\n",
    "    tokenizer_name = \"bert-base-uncased\" # フォールバックとして定義\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        print(f\"フォールバックとしてトークナイザ '{tokenizer_name}' を新規にロードしました。\")\n",
    "    except Exception as e:\n",
    "        print(f\"フォールバックのトークナイザロード中にエラー: {e}\")\n",
    "        raise NameError(\"BERT Tokenizer is not available.\")\n",
    "\n",
    "\n",
    "# --- SST-2データセットのパス設定 (問題60, 71と同様) ---\n",
    "# 問題60でSST-2データを展開した親ディレクトリへのパスを想定\n",
    "base_data_dir_ch9 = '../data/SST-2_data' \n",
    "train_file_path_ch9 = os.path.join(base_data_dir_ch9, \"SST-2/train.tsv\")\n",
    "dev_file_path_ch9 = os.path.join(base_data_dir_ch9, \"SST-2/dev.tsv\")\n",
    "\n",
    "# データセットが存在するか確認 (問題60でダウンロード・展開済みのはず)\n",
    "if not (os.path.exists(train_file_path_ch9) and os.path.exists(dev_file_path_ch9)):\n",
    "    print(f\"エラー: {train_file_path_ch9} または {dev_file_path_ch9} が見つかりません。\")\n",
    "    print(\"問題60を先に実行して、SST-2データセットをダウンロード・展開してください。\")\n",
    "    # 処理を中断\n",
    "    raise FileNotFoundError(\"SST-2 dataset files not found.\")\n",
    "\n",
    "# --- ここから問題85の処理 ---\n",
    "MAX_LENGTH = 128 # BERTに入力する最大トークン長 (適宜調整)\n",
    "\n",
    "def process_data_for_bert(file_path, tokenizer_bert, max_len, dataset_name=\"データセット\"):\n",
    "    \"\"\"SST-2データを読み込み、BERT用にトークン化・整形する関数\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        print(f\"\\n--- {dataset_name} ({os.path.basename(file_path)}) ---\")\n",
    "        print(f\"元の事例数: {len(df)}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"エラー: ファイル '{file_path}' が見つかりません。\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ファイル '{file_path}' の読み込み中にエラー: {e}\")\n",
    "        return None\n",
    "\n",
    "    # BERTトークナイザはテキストのリストを直接扱える\n",
    "    texts = df['sentence'].tolist()\n",
    "    labels = df['label'].tolist()\n",
    "\n",
    "    # トークン化 (paddingとtruncationを同時に行う)\n",
    "    # tokenizer() は辞書を返す。キー: 'input_ids', 'token_type_ids', 'attention_mask'\n",
    "    print(f\"{dataset_name}のテキストをトークン化しています (max_length={max_len})...\")\n",
    "    encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    \n",
    "    # PyTorchのDatasetで扱いやすいように、各要素を辞書とするリストに変換することもできるし、\n",
    "    # この encodings と labels を使って直接Datasetオブジェクトを作ることもできる。\n",
    "    # ここでは、問題文の指示「全てのテキストはトークン列に変換せよ」に従い、\n",
    "    # encodings['input_ids'] を主に見る。\n",
    "    # labels もテンソルに変換しておく。\n",
    "    \n",
    "    dataset_for_bert = {\n",
    "        'input_ids': encodings['input_ids'],\n",
    "        'attention_mask': encodings['attention_mask'],\n",
    "        'labels': torch.tensor(labels) # ラベルをテンソルに\n",
    "    }\n",
    "    # Token Type IDs はSST-2のような単一文入力タスクでは通常不要なので、含めなくても良い場合が多い\n",
    "    if 'token_type_ids' in encodings:\n",
    "         dataset_for_bert['token_type_ids'] = encodings['token_type_ids']\n",
    "\n",
    "    print(f\"{dataset_name}の処理完了。\")\n",
    "    print(f\"  input_ids の形状: {dataset_for_bert['input_ids'].shape}\") # (事例数, max_length)\n",
    "    print(f\"  attention_mask の形状: {dataset_for_bert['attention_mask'].shape}\")\n",
    "    print(f\"  labels の形状: {dataset_for_bert['labels'].shape}\")\n",
    "    \n",
    "    return dataset_for_bert\n",
    "\n",
    "\n",
    "# 訓練データの処理\n",
    "train_bert_dataset = process_data_for_bert(train_file_path_ch9, tokenizer, MAX_LENGTH, \"訓練データ\")\n",
    "\n",
    "# 開発（検証）データの処理\n",
    "dev_bert_dataset = process_data_for_bert(dev_file_path_ch9, tokenizer, MAX_LENGTH, \"開発データ\")\n",
    "\n",
    "# 最初の数件のinput_idsと対応するテキスト、ラベルを表示して確認 (任意)\n",
    "if train_bert_dataset:\n",
    "    print(\"\\n訓練データの最初の事例（トークンIDとデコード結果）:\")\n",
    "    idx_to_show = 0\n",
    "    sample_input_ids = train_bert_dataset['input_ids'][idx_to_show]\n",
    "    sample_label = train_bert_dataset['labels'][idx_to_show]\n",
    "    \n",
    "    # 元のテキストを取得する部分をf-stringの外に出す\n",
    "    # df_train_temp はこのブロック内でのみ使用する一時的なDataFrame\n",
    "    try:\n",
    "        df_train_temp = pd.read_csv(train_file_path_ch9, sep='\\t')\n",
    "        original_text_from_df = df_train_temp.iloc[idx_to_show]['sentence']\n",
    "    except Exception as e:\n",
    "        original_text_from_df = f\"(元のテキストの読み込みに失敗: {e})\"\n",
    "\n",
    "    print(f\"  Input IDs: {sample_input_ids.tolist()}\")\n",
    "    print(f\"  Decoded Text: {tokenizer.decode(sample_input_ids, skip_special_tokens=True)}\")\n",
    "    # ★★★ 修正箇所 ★★★\n",
    "    print(f\"  Original Text (from df): {original_text_from_df}\") \n",
    "    print(f\"  Label: {sample_label.item()}\")\n",
    "\n",
    "# これで train_bert_dataset と dev_bert_dataset に\n",
    "# BERTモデルでのファインチューニングに適した形式のデータが格納されました。\n",
    "# これらは後の問題で使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiXmLuWpD3_Q"
   },
   "source": [
    "## 86. ミニバッチの作成\n",
    "\n",
    "85で読み込んだ訓練データの一部（例えば冒頭の4事例）に対して、パディングなどの処理を行い、トークン列の長さを揃えてミニバッチを構成せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの最初の4事例から構成されるミニバッチ（の一部）を表示します。\n",
      "(最大シーケンス長 MAX_LENGTH = 128 にパディング/切り詰めされています)\n",
      "\n",
      "Input IDs (最初の4事例):\n",
      "tensor([[  101,  5342,  2047,  3595,  8496,  2013,  1996, 18643,  3197,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3397,  2053, 15966,  1010,  2069,  4450,  2098, 18201,  2015,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  2008,  7459,  2049,  3494,  1998, 10639,  2015,  2242,  2738,\n",
      "          3376,  2055,  2529,  3267,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  3464, 12580,  8510,  2000,  3961,  1996,  2168,  2802,   102,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]])\n",
      "形状: torch.Size([4, 66])\n",
      "\n",
      "Attention Mask (最初の4事例):\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "形状: torch.Size([4, 66])\n",
      "\n",
      "Labels (最初の4事例):\n",
      "tensor([0, 0, 1, 0])\n",
      "形状: torch.Size([4])\n",
      "\n",
      "各事例のデコード結果 (パディングと特殊トークン含む):\n",
      "事例 1:\n",
      "  Input IDs (raw): [101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Decoded (with special, incl. padding if not skipped by decode): [CLS] hide new secretions from the parental units [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "  Decoded (actual tokens, skip special): hide new secretions from the parental units\n",
      "  Label: 0\n",
      "事例 2:\n",
      "  Input IDs (raw): [101, 3397, 2053, 15966, 1010, 2069, 4450, 2098, 18201, 2015, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Decoded (with special, incl. padding if not skipped by decode): [CLS] contains no wit, only labored gags [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "  Decoded (actual tokens, skip special): contains no wit, only labored gags\n",
      "  Label: 0\n",
      "事例 3:\n",
      "  Input IDs (raw): [101, 2008, 7459, 2049, 3494, 1998, 10639, 2015, 2242, 2738, 3376, 2055, 2529, 3267, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Decoded (with special, incl. padding if not skipped by decode): [CLS] that loves its characters and communicates something rather beautiful about human nature [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "  Decoded (actual tokens, skip special): that loves its characters and communicates something rather beautiful about human nature\n",
      "  Label: 1\n",
      "事例 4:\n",
      "  Input IDs (raw): [101, 3464, 12580, 8510, 2000, 3961, 1996, 2168, 2802, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "  Decoded (with special, incl. padding if not skipped by decode): [CLS] remains utterly satisfied to remain the same throughout [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "  Decoded (actual tokens, skip special): remains utterly satisfied to remain the same throughout\n",
      "  Label: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer # tokenizerがロード済みであることを期待\n",
    "\n",
    "# --- 前提となる変数 (問題85から) ---\n",
    "# train_bert_dataset: 問題85で作成した、トークン化・パディング済みの訓練データ全体を格納した辞書\n",
    "#                     {'input_ids': tensor, 'attention_mask': tensor, 'labels': tensor}\n",
    "# tokenizer: 問題80 (または83, 85) でロードした AutoTokenizer のインスタンス\n",
    "# MAX_LENGTH: 問題85で使用した最大シーケンス長\n",
    "\n",
    "# 前提変数が存在するか確認\n",
    "if 'train_bert_dataset' not in locals() or not train_bert_dataset or \\\n",
    "   'tokenizer' not in locals() or tokenizer is None or \\\n",
    "   'MAX_LENGTH' not in locals():\n",
    "    print(\"エラー: 必要な変数 ('train_bert_dataset', 'tokenizer', 'MAX_LENGTH') が定義されていません。\")\n",
    "    print(\"問題85を先に実行して、これらの変数を準備してください。\")\n",
    "    raise NameError(\"Required variables from Problem 85 are not defined.\")\n",
    "\n",
    "# --- ここから問題86の処理 ---\n",
    "\n",
    "num_samples_to_show = 4 # 問題文の指示「冒頭の4事例」\n",
    "\n",
    "if len(train_bert_dataset['input_ids']) < num_samples_to_show:\n",
    "    print(f\"警告: 訓練データには{num_samples_to_show}件未満の事例しかありません。表示件数を調整します。\")\n",
    "    num_samples_to_show = len(train_bert_dataset['input_ids'])\n",
    "\n",
    "if num_samples_to_show > 0:\n",
    "    print(f\"訓練データの最初の{num_samples_to_show}事例から構成されるミニバッチ（の一部）を表示します。\")\n",
    "    print(f\"(最大シーケンス長 MAX_LENGTH = {MAX_LENGTH} にパディング/切り詰めされています)\")\n",
    "\n",
    "    # 冒頭4事例を抽出\n",
    "    sample_input_ids = train_bert_dataset['input_ids'][:num_samples_to_show]\n",
    "    sample_attention_mask = train_bert_dataset['attention_mask'][:num_samples_to_show]\n",
    "    sample_labels = train_bert_dataset['labels'][:num_samples_to_show]\n",
    "\n",
    "    print(\"\\nInput IDs (最初の4事例):\")\n",
    "    print(sample_input_ids)\n",
    "    print(f\"形状: {sample_input_ids.shape}\") # 期待: (4, MAX_LENGTH)\n",
    "\n",
    "    print(\"\\nAttention Mask (最初の4事例):\")\n",
    "    print(sample_attention_mask)\n",
    "    print(f\"形状: {sample_attention_mask.shape}\") # 期待: (4, MAX_LENGTH)\n",
    "    \n",
    "    print(\"\\nLabels (最初の4事例):\")\n",
    "    print(sample_labels)\n",
    "    print(f\"形状: {sample_labels.shape}\") # 期待: (4) または (4,1)など\n",
    "\n",
    "    print(\"\\n各事例のデコード結果 (パディングと特殊トークン含む):\")\n",
    "    for i in range(num_samples_to_show):\n",
    "        ids = sample_input_ids[i]\n",
    "        # パディング部分を除いた実際のトークンを見るためにattention_maskを利用\n",
    "        actual_tokens_ids = ids[sample_attention_mask[i] == 1] \n",
    "        \n",
    "        print(f\"事例 {i+1}:\")\n",
    "        print(f\"  Input IDs (raw): {ids.tolist()}\")\n",
    "        print(f\"  Decoded (with special, incl. padding if not skipped by decode): {tokenizer.decode(ids)}\")\n",
    "        print(f\"  Decoded (actual tokens, skip special): {tokenizer.decode(actual_tokens_ids, skip_special_tokens=True)}\")\n",
    "        print(f\"  Label: {sample_labels[i].item()}\")\n",
    "else:\n",
    "    print(\"表示する訓練データがありません。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4nrV6bqD-m9"
   },
   "source": [
    "## 87. ファインチューニング\n",
    "\n",
    "訓練セットを用い、事前学習済みモデルを極性分析タスク向けにファインチューニングせよ。検証セット上でファインチューニングされたモデルの正解率を計測せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "事前学習済みモデル 'bert-base-uncased' (分類用) をロードしました。\n",
      "\n",
      "GPUが利用できません。CPUを使用します。\n",
      "\n",
      "ファインチューニング (バッチサイズ=16, エポック数=3) を開始します...\n",
      "\n",
      "--- Epoch 1/3 ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader # DataLoaderも一緒にインポートしておくと良い\n",
    "from torch.utils.data import DataLoader, TensorDataset # TensorDataset を使う場合\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import os\n",
    "import pandas as pd # データ構造の確認や、万が一の再読み込み用\n",
    "\n",
    "# --- 前提となる変数・データ (問題80, 85から) ---\n",
    "# tokenizer: 問題80または85でロードした AutoTokenizer のインスタンス\n",
    "# train_bert_dataset: 問題85で作成した訓練データ {'input_ids': tensor, 'attention_mask': tensor, 'labels': tensor}\n",
    "# dev_bert_dataset: 問題85で作成した検証データ {'input_ids': tensor, 'attention_mask': tensor, 'labels': tensor}\n",
    "# MAX_LENGTH: 問題85で使用した最大シーケンス長\n",
    "\n",
    "# --- 変数・クラスが現在のセッションに存在するか確認 ---\n",
    "required_vars_p87 = ['tokenizer', 'train_bert_dataset', 'dev_bert_dataset', 'MAX_LENGTH']\n",
    "for var_name in required_vars_p87:\n",
    "    if var_name not in locals() or locals()[var_name] is None:\n",
    "        print(f\"エラー: 前提となる変数 '{var_name}' が定義されていないかNoneです。\")\n",
    "        print(\"問題80および85を先に実行してください。\")\n",
    "        raise NameError(f\"Variable '{var_name}' is not defined or None.\")\n",
    "\n",
    "# --- ここから問題87の処理 ---\n",
    "\n",
    "# 1. モデルの準備\n",
    "model_name_finetune = \"bert-base-uncased\" # または他の適切なBERTモデル名\n",
    "try:\n",
    "    # num_labels=2 で2値分類用のヘッドを持つモデルをロード\n",
    "    model_ft = AutoModelForSequenceClassification.from_pretrained(model_name_finetune, num_labels=2)\n",
    "    print(f\"事前学習済みモデル '{model_name_finetune}' (分類用) をロードしました。\")\n",
    "except Exception as e:\n",
    "    print(f\"モデル '{model_name_finetune}' のロード中にエラーが発生しました: {e}\")\n",
    "    raise\n",
    "\n",
    "# 2. データセットとデータローダーの準備\n",
    "# 問題85で train_bert_dataset と dev_bert_dataset は既に必要なキーを持つ辞書として作成済み\n",
    "# これらをPyTorchのDatasetオブジェクトに変換する\n",
    "class BertSST2Dataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings # トークナイザからの出力辞書 {'input_ids', 'attention_mask', ...}\n",
    "        self.labels = labels     # ラベルのテンソル\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset_ft = BertSST2Dataset(\n",
    "    {'input_ids': train_bert_dataset['input_ids'], 'attention_mask': train_bert_dataset['attention_mask']}, \n",
    "    train_bert_dataset['labels']\n",
    ")\n",
    "dev_dataset_ft = BertSST2Dataset(\n",
    "    {'input_ids': dev_bert_dataset['input_ids'], 'attention_mask': dev_bert_dataset['attention_mask']},\n",
    "    dev_bert_dataset['labels']\n",
    ")\n",
    "\n",
    "batch_size_ft = 16 # ファインチューニング時のバッチサイズ (GPUメモリに応じて調整)\n",
    "train_dataloader_ft = DataLoader(train_dataset_ft, batch_size=batch_size_ft, shuffle=True)\n",
    "dev_dataloader_ft = DataLoader(dev_dataset_ft, batch_size=batch_size_ft, shuffle=False)\n",
    "\n",
    "\n",
    "# 3. 学習の準備\n",
    "# GPUの利用設定\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"\\nGPU ({torch.cuda.get_device_name(0)}) を使用します。\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"\\nGPUが利用できません。CPUを使用します。\")\n",
    "\n",
    "model_ft.to(device) # モデルをGPUへ\n",
    "\n",
    "# 最適化アルゴリズムと学習率スケジューラ\n",
    "optimizer_ft = optim.AdamW(model_ft.parameters(), lr=2e-5) # AdamWと小さめの学習率が一般的\n",
    "num_epochs_ft = 3 # ファインチューニングのエポック数 (通常は少なめ)\n",
    "total_steps = len(train_dataloader_ft) * num_epochs_ft\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer_ft, \n",
    "                                            num_warmup_steps=0, # ウォームアップステップ数 (0も可)\n",
    "                                            num_training_steps=total_steps)\n",
    "# 損失関数はモデル内部で計算されることが多い (CrossEntropyLoss相当)\n",
    "# もしモデルがロジットのみを返し、ラベルが [0, 1] の整数なら以下のように自分で定義も可能\n",
    "# criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "print(f\"\\nファインチューニング (バッチサイズ={batch_size_ft}, エポック数={num_epochs_ft}) を開始します...\")\n",
    "start_time_ft = time.time()\n",
    "\n",
    "# 4. ファインチューニング（学習ループ）\n",
    "for epoch in range(num_epochs_ft):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{num_epochs_ft} ---\")\n",
    "    model_ft.train() # モデルを学習モードに\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataloader_ft):\n",
    "        optimizer_ft.zero_grad()\n",
    "        \n",
    "        # データをGPUへ\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # モデルのフォワードパス\n",
    "        # AutoModelForSequenceClassification は通常、損失も一緒に出力する\n",
    "        outputs = model_ft(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        \n",
    "        loss = outputs.loss # モデル出力から損失を取得\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_ft.step()\n",
    "        scheduler.step() # 学習率を更新\n",
    "        \n",
    "        if (batch_idx + 1) % (len(train_dataloader_ft) // 10) == 0 or (batch_idx + 1) == len(train_dataloader_ft): # 約10%ごとと最後に表示\n",
    "            print(f\"  Batch [{batch_idx+1}/{len(train_dataloader_ft)}], Avg Train Loss so far: {total_train_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader_ft)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs_ft}] 完了, 平均訓練損失: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # エポックごとに検証データで評価\n",
    "    model_ft.eval() # モデルを評価モードに\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dev_dataloader_ft:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model_ft(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_eval_loss += loss.item()\n",
    "            \n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            total_eval_accuracy += accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy()) * labels.size(0) # バッチ内の正解数を加算\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(dev_dataset_ft)\n",
    "    avg_val_loss = total_eval_loss / len(dev_dataloader_ft)\n",
    "    print(f\"  Epoch [{epoch+1}/{num_epochs_ft}], 検証データ: 平均損失={avg_val_loss:.4f}, 正解率={avg_val_accuracy:.4f}\")\n",
    "\n",
    "end_time_ft = time.time()\n",
    "print(f\"\\nファインチューニングが完了しました。所要時間: {end_time_ft - start_time_ft:.2f} 秒\")\n",
    "\n",
    "# 5. 最終評価 (学習完了後のモデルで再度検証セットの正解率を計測)\n",
    "print(\"\\n--- 最終評価 (開発セット、ファインチューニング後) ---\")\n",
    "model_ft.eval()\n",
    "final_predictions = []\n",
    "final_true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in dev_dataloader_ft:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model_ft(input_ids, attention_mask=attention_mask) # ラベルは渡さない\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        final_predictions.extend(predictions.cpu().numpy())\n",
    "        final_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "final_accuracy = accuracy_score(final_true_labels, final_predictions)\n",
    "print(f\"開発セットにおける最終正解率 (ファインチューニング後): {final_accuracy:.4f}\")\n",
    "print(f\"  正解した事例数: {int(final_accuracy * len(final_true_labels))}\")\n",
    "print(f\"  総事例数: {len(final_true_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OqDN0G2UqFJ"
   },
   "source": [
    "## 88. 極性分析\n",
    "\n",
    "問題87でファインチューニングされたモデルを用いて、以下の文の極性を予測せよ。\n",
    "\n",
    "- \"The movie was full of incomprehensibilities.\"\n",
    "- \"The movie was full of fun.\"\n",
    "- \"The movie was full of excitement.\"\n",
    "- \"The movie was full of crap.\"\n",
    "- \"The movie was full of rubbish.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F # ソフトマックス用 (任意)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification # 再ロードする場合\n",
    "\n",
    "# --- 前提となる変数 (問題87から) ---\n",
    "# model_ft: 問題87でファインチューニング済みのモデル\n",
    "# tokenizer: 問題80または85でロードしたトークナイザ\n",
    "# device: 問題87で使用したデバイス ('cuda' または 'cpu')\n",
    "# MAX_LENGTH: 問題85で使用した最大シーケンス長 (トークナイズ時に使用)\n",
    "\n",
    "\n",
    "# --- 変数・クラスが現在のセッションに存在するか確認 ---\n",
    "if 'model_ft' not in locals() or model_ft is None:\n",
    "    print(\"エラー: ファインチューニング済みモデル 'model_ft' が定義されていません。\")\n",
    "    print(\"問題87を先に実行して、モデルを準備（学習またはロード）してください。\")\n",
    "    raise NameError(\"Fine-tuned model 'model_ft' is not defined.\")\n",
    "\n",
    "if 'tokenizer' not in locals() or tokenizer is None:\n",
    "    print(\"エラー: トークナイザ 'tokenizer' が定義されていません。\")\n",
    "    print(\"問題80または85を先に実行して、トークナイザを準備してください。\")\n",
    "    raise NameError(\"Tokenizer is not defined.\")\n",
    "\n",
    "if 'device' not in locals() or device is None:\n",
    "    print(\"エラー: デバイス 'device' が定義されていません。問題87のデバイス設定を確認してください。\")\n",
    "    # フォールバックとしてCPUを設定する例 (GPUが推奨)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"フォールバックデバイスを '{device}' に設定しました。\")\n",
    "\n",
    "if 'MAX_LENGTH' not in locals() or MAX_LENGTH is None:\n",
    "    print(\"エラー: 'MAX_LENGTH' が定義されていません。問題85のMAX_LENGTH設定を確認してください。\")\n",
    "    MAX_LENGTH = 128 # フォールバック値\n",
    "    print(f\"フォールバックとして MAX_LENGTH を {MAX_LENGTH} に設定しました。\")\n",
    "\n",
    "# --- ここから問題88の処理 ---\n",
    "\n",
    "# 2. 予測対象の文リスト\n",
    "sentences_to_predict = [\n",
    "    \"The movie was full of incomprehensibilities.\",\n",
    "    \"The movie was full of fun.\",\n",
    "    \"The movie was full of excitement.\",\n",
    "    \"The movie was full of crap.\",\n",
    "    \"The movie was full of rubbish.\"\n",
    "]\n",
    "\n",
    "# ラベルのマッピング (0: ネガティブ, 1: ポジティブ)\n",
    "label_map = {0: \"ネガティブ\", 1: \"ポジティブ\"}\n",
    "\n",
    "print(\"\\n指定された文の極性分析を行います...\")\n",
    "\n",
    "# 3. 各文に対する極性予測\n",
    "model_ft.eval() # モデルを評価モードに\n",
    "with torch.no_grad(): # 勾配計算を無効に\n",
    "    for i, sentence in enumerate(sentences_to_predict):\n",
    "        # テキストをトークン化\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", \n",
    "                           padding='max_length', # バッチ処理ではないが、一貫性のためmax_lengthにパディング\n",
    "                           truncation=True, \n",
    "                           max_length=MAX_LENGTH)\n",
    "        \n",
    "        # データをモデルと同じデバイスに送る\n",
    "        input_ids = inputs['input_ids'].to(device)\n",
    "        attention_mask = inputs['attention_mask'].to(device)\n",
    "        \n",
    "        # モデルで予測\n",
    "        outputs = model_ft(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits # (バッチサイズ, num_labels) -> (1, 2) の形状\n",
    "        \n",
    "        # 予測ラベルを取得 (最もスコアが高いクラスのインデックス)\n",
    "        predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "        predicted_label_name = label_map.get(predicted_class_id, \"不明なラベル\")\n",
    "        \n",
    "        # (任意) 各クラスの確率を取得\n",
    "        probabilities = F.softmax(logits, dim=-1)[0] # バッチサイズ1なので[0]で最初の要素を取得\n",
    "        prob_negative = probabilities[0].item() # ラベル0がネガティブと仮定\n",
    "        prob_positive = probabilities[1].item() # ラベル1がポジティブと仮定\n",
    "        # 注意: model_ft.config.id2label や label2id で正確なマッピングを確認した方が良い場合もある\n",
    "        \n",
    "        print(f\"\\n文 {i+1}: \\\"{sentence}\\\"\")\n",
    "        print(f\"  予測極性: {predicted_label_name} (ID: {predicted_class_id})\")\n",
    "        print(f\"  確率 (ネガティブ): {prob_negative:.4f}\")\n",
    "        print(f\"  確率 (ポジティブ): {prob_positive:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EruVW7JaapIv"
   },
   "source": [
    "## 89. アーキテクチャの変更\n",
    "\n",
    "問題87とは異なるアーキテクチャ（例えば[CLS]トークンを用いるか、各トークンの最大値プーリングを用いるなど）の分類モデルを設計し、事前学習済みモデルを極性分析タスク向けにファインチューニングせよ。検証セット上でファインチューニングされたモデルの正解率を計測せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup # AutoModelを使用\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- 前提となる変数・クラス・関数の定義 (問題87と同様) ---\n",
    "# tokenizer, train_bert_dataset, dev_bert_dataset, MAX_LENGTH\n",
    "# BertSST2Dataset クラス\n",
    "\n",
    "# --- 変数・クラスが現在のセッションに存在するか確認 ---\n",
    "required_vars_p89 = ['tokenizer', 'train_bert_dataset', 'dev_bert_dataset', 'MAX_LENGTH']\n",
    "for var_name in required_vars_p89:\n",
    "    if var_name not in locals() or locals()[var_name] is None:\n",
    "        print(f\"エラー: 前提となる変数 '{var_name}' が定義されていません。\")\n",
    "        raise NameError(f\"Variable '{var_name}' is not defined or None.\")\n",
    "\n",
    "if 'BertSST2Dataset' not in locals():\n",
    "        print(f\"エラー: 前提となるクラス 'BertSST2Dataset' が定義されていません。\")\n",
    "        raise NameError(f\"Class 'BertSST2Dataset' is not defined.\")\n",
    "\n",
    "# --- ここから問題89の処理 ---\n",
    "\n",
    "# 1. 新しいアーキテクチャのモデルクラス定義 (平均プーリング)\n",
    "class BertMeanPoolingClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_labels, dropout_rate=0.1):\n",
    "        super(BertMeanPoolingClassifier, self).__init__()\n",
    "        # 事前学習済みBERTモデルをロード (分類ヘッドなし)\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        # BERTの隠れ層サイズを取得 (例: bert-base-uncased なら 768)\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size \n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # 分類用の線形層\n",
    "        self.classifier = nn.Linear(self.bert_hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # BERTモデルから最終層の隠れ状態を取得\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # 平均プーリング (attention_mask を利用してパディングを無視)\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9) # ゼロ除算を避ける\n",
    "        mean_pooled_output = sum_embeddings / sum_mask\n",
    "        # mean_pooled_output: (batch_size, hidden_size)\n",
    "        \n",
    "        # ドロップアウトと分類\n",
    "        pooled_output_dropout = self.dropout(mean_pooled_output)\n",
    "        logits = self.classifier(pooled_output_dropout) # (batch_size, num_labels)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# --- モデルと学習の準備 ---\n",
    "model_name_p89 = \"bert-base-uncased\" # 問題87と同じ事前学習モデルを使用\n",
    "num_labels_p89 = 2 # ポジネガ2値分類\n",
    "\n",
    "# デバイス設定\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU ({torch.cuda.get_device_name(0)}) を使用します。\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPUが利用できません。CPUを使用します。\")\n",
    "\n",
    "# モデルのインスタンス化とデバイスへの転送\n",
    "model_meanpool = BertMeanPoolingClassifier(model_name_p89, num_labels_p89)\n",
    "model_meanpool.to(device)\n",
    "print(f\"\\n平均プーリングを用いたBERT分類モデル '{model_name_p89}' をロードし、デバイスに転送しました。\")\n",
    "print(model_meanpool)\n",
    "\n",
    "\n",
    "# データローダーの準備 (問題87と同様)\n",
    "# BertSST2Dataset は {key: val[idx]} を返すので、モデルの入力に合わせて調整が必要な場合がある\n",
    "# BertMeanPoolingClassifier は input_ids と attention_mask を想定\n",
    "class BertInputDataset(Dataset): # BertSST2Dataset を少し変更\n",
    "    def __init__(self, encodings_dict, labels_tensor):\n",
    "        self.input_ids = encodings_dict['input_ids']\n",
    "        self.attention_mask = encodings_dict['attention_mask']\n",
    "        # token_type_ids があればそれも\n",
    "        self.token_type_ids = encodings_dict.get('token_type_ids', None) # なければNone\n",
    "        self.labels = labels_tensor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            'input_ids': self.input_ids[idx].clone().detach(),\n",
    "            'attention_mask': self.attention_mask[idx].clone().detach()\n",
    "        }\n",
    "        if self.token_type_ids is not None:\n",
    "             item['token_type_ids'] = self.token_type_ids[idx].clone().detach()\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset_mp = BertInputDataset(\n",
    "    {'input_ids': train_bert_dataset['input_ids'], \n",
    "     'attention_mask': train_bert_dataset['attention_mask'],\n",
    "     'token_type_ids': train_bert_dataset.get('token_type_ids', None)}, # token_type_idsも渡す\n",
    "    train_bert_dataset['labels']\n",
    ")\n",
    "dev_dataset_mp = BertInputDataset(\n",
    "    {'input_ids': dev_bert_dataset['input_ids'], \n",
    "     'attention_mask': dev_bert_dataset['attention_mask'],\n",
    "     'token_type_ids': dev_bert_dataset.get('token_type_ids', None)},\n",
    "    dev_bert_dataset['labels']\n",
    ")\n",
    "\n",
    "batch_size_mp = 16\n",
    "train_dataloader_mp = DataLoader(train_dataset_mp, batch_size=batch_size_mp, shuffle=True)\n",
    "dev_dataloader_mp = DataLoader(dev_dataset_mp, batch_size=batch_size_mp, shuffle=False)\n",
    "\n",
    "\n",
    "# 学習パラメータ\n",
    "learning_rate_mp = 2e-5\n",
    "num_epochs_mp = 3 # 問題87と同程度のエポック数で比較\n",
    "\n",
    "# 損失関数 (クラス数が2なのでCrossEntropyLossが一般的)\n",
    "# モデルの出力ロジットは (batch_size, num_labels) の形状になる\n",
    "criterion_mp = nn.CrossEntropyLoss() \n",
    "optimizer_mp = optim.AdamW(model_meanpool.parameters(), lr=learning_rate_mp)\n",
    "total_steps_mp = len(train_dataloader_mp) * num_epochs_mp\n",
    "scheduler_mp = get_linear_schedule_with_warmup(optimizer_mp, num_warmup_steps=0, num_training_steps=total_steps_mp)\n",
    "\n",
    "print(f\"\\n平均プーリングモデルのファインチューニング (バッチサイズ={batch_size_mp}, エポック数={num_epochs_mp}) を開始します...\")\n",
    "start_time_mp = time.time()\n",
    "\n",
    "# --- 学習ループ (問題87とほぼ同じだが、損失計算の仕方が少し異なる可能性) ---\n",
    "for epoch in range(num_epochs_mp):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{num_epochs_mp} ---\")\n",
    "    model_meanpool.train()\n",
    "    total_train_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_dataloader_mp):\n",
    "        optimizer_mp.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device) # ラベルは (batch_size) の形状で、クラスインデックス (0 or 1)\n",
    "        # token_type_ids は今回のモデルでは使わないが、渡せるようにしておく\n",
    "        # token_type_ids = batch.get('token_type_ids', None)\n",
    "        # if token_type_ids is not None:\n",
    "        #     token_type_ids = token_type_ids.to(device)\n",
    "        \n",
    "        # logits = model_meanpool(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # AutoModelは **kwargs を受け付けるので、token_type_ids も渡せる\n",
    "        model_inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        # if token_type_ids is not None: # BertMeanPoolingClassifier側で **kwargs を受け取らないので、直接渡せない\n",
    "        #     model_inputs['token_type_ids'] = token_type_ids\n",
    "        logits = model_meanpool(**model_inputs) # **model_inputs で展開して渡す\n",
    "\n",
    "        loss = criterion_mp(logits, labels) # CrossEntropyLossはロジットと整数のラベルを期待\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer_mp.step()\n",
    "        scheduler_mp.step()\n",
    "        \n",
    "        if (batch_idx + 1) % (len(train_dataloader_mp) // 10) == 0 or (batch_idx + 1) == len(train_dataloader_mp):\n",
    "            print(f\"  Batch [{batch_idx+1}/{len(train_dataloader_mp)}], Avg Train Loss so far: {total_train_loss / (batch_idx+1):.4f}\")\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader_mp)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs_mp}] 完了, 平均訓練損失: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # エポックごとに検証データで評価\n",
    "    model_meanpool.eval()\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dev_dataloader_mp:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            # token_type_ids = batch.get('token_type_ids', None)\n",
    "            # if token_type_ids is not None:\n",
    "            #     token_type_ids = token_type_ids.to(device)\n",
    "            \n",
    "            model_inputs_dev = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "            # if token_type_ids is not None:\n",
    "            #     model_inputs_dev['token_type_ids'] = token_type_ids\n",
    "            logits = model_meanpool(**model_inputs_dev)\n",
    "            \n",
    "            loss = criterion_mp(logits, labels)\n",
    "            total_eval_loss += loss.item()\n",
    "            \n",
    "            predictions = torch.argmax(logits, dim=-1) # (batch_size) の形状\n",
    "            total_eval_accuracy += accuracy_score(labels.cpu().numpy(), predictions.cpu().numpy()) * labels.size(0)\n",
    "\n",
    "    avg_val_accuracy = total_eval_accuracy / len(dev_dataset_mp)\n",
    "    avg_val_loss = total_eval_loss / len(dev_dataloader_mp)\n",
    "    print(f\"  Epoch [{epoch+1}/{num_epochs_mp}], 検証データ: 平均損失={avg_val_loss:.4f}, 正解率={avg_val_accuracy:.4f}\")\n",
    "\n",
    "end_time_mp = time.time()\n",
    "print(f\"\\n平均プーリングモデルのファインチューニングが完了しました。所要時間: {end_time_mp - start_time_mp:.2f} 秒\")\n",
    "\n",
    "# 5. 最終評価\n",
    "print(\"\\n--- 最終評価 (開発セット、平均プーリングモデル) ---\")\n",
    "model_meanpool.eval()\n",
    "final_predictions_mp = []\n",
    "final_true_labels_mp = []\n",
    "with torch.no_grad():\n",
    "    for batch in dev_dataloader_mp:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # token_type_ids = batch.get('token_type_ids', None)\n",
    "        # if token_type_ids is not None:\n",
    "        #     token_type_ids = token_type_ids.to(device)\n",
    "\n",
    "        model_inputs_final_eval = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        # if token_type_ids is not None:\n",
    "        #     model_inputs_final_eval['token_type_ids'] = token_type_ids\n",
    "        logits = model_meanpool(**model_inputs_final_eval)\n",
    "        \n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        final_predictions_mp.extend(predictions.cpu().numpy())\n",
    "        final_true_labels_mp.extend(labels.cpu().numpy())\n",
    "\n",
    "final_accuracy_mp = accuracy_score(final_true_labels_mp, final_predictions_mp)\n",
    "print(f\"開発セットにおける最終正解率 (平均プーリングモデル): {final_accuracy_mp:.4f}\")\n",
    "print(f\"  正解した事例数: {int(final_accuracy_mp * len(final_true_labels_mp))}\")\n",
    "print(f\"  総事例数: {len(final_true_labels_mp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00a3664cb9fc4f6b872e586ada24783e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_576cd79ab51f438f87a0e360c9b4e550",
       "IPY_MODEL_100af9d57e694e4c9a348f06f47e6553",
       "IPY_MODEL_5c8268613d26465fab7b7f6ff5ef4980"
      ],
      "layout": "IPY_MODEL_101b455e0a414c66bd2acb1cf11b8eff"
     }
    },
    "0165770850664460be47ce63ec7bb10c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06333de8d623439f9ef685824aee79a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "095b7e03e9e643e2bd43acfdf8e371d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e206d47e7454eadacf7ff051df48ec5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f48a0b8ae6a42ba95335ccd0515ffb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "100af9d57e694e4c9a348f06f47e6553": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b52ca397026d44a3b48d49454d09fff4",
      "max": 20810,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d710228ca5d4fcca13ea790e9ce5702",
      "value": 20810
     }
    },
    "101b455e0a414c66bd2acb1cf11b8eff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13eca10db5c2485697b998e80041d371": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14fe192eea054d75ba7b4ed2b0bec185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "166b5bfc9e0f41eb8c6d6be9e8293b3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe54f2430afa48f9994b5b23c2691299",
      "placeholder": "​",
      "style": "IPY_MODEL_97e757709f654334a1ae47c4c095e5ef",
      "value": " 4.20k/4.20k [00:00&lt;00:00, 482kB/s]"
     }
    },
    "17e21334f8ca4da79249424865521139": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f037b7aeb70043ce9b2151418f51d82b",
       "IPY_MODEL_cc26951539484e00b49d41e2d813bcba",
       "IPY_MODEL_166b5bfc9e0f41eb8c6d6be9e8293b3b"
      ],
      "layout": "IPY_MODEL_2524e77233f44cc682ce20d43489a26f"
     }
    },
    "1952faddf4f1486cad7ee8d93a11109b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b373907d135d4404835e49fcc0f6d979",
       "IPY_MODEL_6ee70f367ebc461eac51e9e36a4a3c38",
       "IPY_MODEL_a5bde82622584e9a86423d57cf9bb1b5"
      ],
      "layout": "IPY_MODEL_b5819c101ac84f0787c1b40698d590c6"
     }
    },
    "1ac8a7ab34f540389abe8a0f3f995a4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1dd44c6676f3409ab04184db47e7bf6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ec5589c6cd74477804333af9b8fce09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2524e77233f44cc682ce20d43489a26f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26954538cb9c41dc84d36790e1bfff33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_812299fc10a34fd2b2352719d50edc3a",
      "placeholder": "​",
      "style": "IPY_MODEL_06333de8d623439f9ef685824aee79a0",
      "value": "model.safetensors: 100%"
     }
    },
    "27758ef3feba449c8f5caf28dd36ba20": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b845f2745bde42c78682293f8f71394b",
      "max": 872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8bf51b065b1e4398865fabc99ff8cb67",
      "value": 872
     }
    },
    "294edb60a94243628b3f423315026651": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c3b1fbc1bce47c088c76fe4ab259b55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3209bb28f1e84dcc94fe83fd3eda1edc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35cc5f3aa2904b8fa5e9831e9d24cc05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e721409660649a08ab4d8682d49c4df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f3a82eb252249c897f0fa20827ae2f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40c3721e762a4d129afa746c3016660b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4404ced79ffe43a2815cc7090220e089": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44a2af8a27ad4bd1aee843cec5727e6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4523838ca360433492abec3e69e96b90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4914703c518c447fa8906f5c278ada32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49846a9589c147c3a8b6851dc4c3c573": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d97bf8945f343caa141904942c1bbc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb958dc4758d4da5b8fe0c561934000d",
      "placeholder": "​",
      "style": "IPY_MODEL_5f6404300bef4adbaf5204a9c925de74",
      "value": "Map: 100%"
     }
    },
    "53265a67cb9b42cc981c451136f0dc19": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54b854d512214c97b46e0c76f742fa70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68063389dddd4044af37d751819866dc",
      "placeholder": "​",
      "style": "IPY_MODEL_1ac8a7ab34f540389abe8a0f3f995a4a",
      "value": "tokenizer.json: 100%"
     }
    },
    "555e3e2bfc08489f8c7fe73fc5a814c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fd0537d82884671a6ca3e53361340c0",
      "placeholder": "​",
      "style": "IPY_MODEL_88cd66a769fb42d6b15e4e5ea1d8c678",
      "value": " 2.13M/2.13M [00:00&lt;00:00, 9.63MB/s]"
     }
    },
    "559ae57d23ba4be0898863eb11bd99e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_659db97b99b646279042826f1d92ce9b",
       "IPY_MODEL_5e43d1d2fc584bb3afd9677604f1ff26",
       "IPY_MODEL_736debb8fc3f4b7ea33ef8c5c32fe1d1"
      ],
      "layout": "IPY_MODEL_5be0869419994fdabc37962b9d7cb95e"
     }
    },
    "55a9d6374eab4a0b93c1c45a2de04254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "572a5fb80e01472cbf3a0739faf21367": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_806643727b2b4d499483d52b4b11339f",
      "placeholder": "​",
      "style": "IPY_MODEL_a5476219e7124a31b0cf78931bf73d98",
      "value": " 599M/599M [00:01&lt;00:00, 340MB/s]"
     }
    },
    "576cd79ab51f438f87a0e360c9b4e550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58699813c0cb4241a7738b8d42aca702",
      "placeholder": "​",
      "style": "IPY_MODEL_4404ced79ffe43a2815cc7090220e089",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "58699813c0cb4241a7738b8d42aca702": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5be0869419994fdabc37962b9d7cb95e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c8268613d26465fab7b7f6ff5ef4980": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f1eece274d34668a9e98697e0c13ee6",
      "placeholder": "​",
      "style": "IPY_MODEL_53265a67cb9b42cc981c451136f0dc19",
      "value": " 20.8k/20.8k [00:00&lt;00:00, 2.26MB/s]"
     }
    },
    "5e43d1d2fc584bb3afd9677604f1ff26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ed8413b46fc4118a3a1c2941cbbe607",
      "max": 1193,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14fe192eea054d75ba7b4ed2b0bec185",
      "value": 1193
     }
    },
    "5f1eece274d34668a9e98697e0c13ee6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f6404300bef4adbaf5204a9c925de74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "606352d97f26491db1b7cb441787e9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_96ea78f250b74d7fb70ba8f450ac94ae",
       "IPY_MODEL_27758ef3feba449c8f5caf28dd36ba20",
       "IPY_MODEL_b0e2a2db5c984ecba03641211b33cdc0"
      ],
      "layout": "IPY_MODEL_9b4d9c39b63741f58284f9cdc32307c9"
     }
    },
    "61665054dda54daca7cc78d4e89a3de8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c632f1c2e4d44990ba30d922632b8d87",
      "max": 598635032,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4e955f9120e4b1b8fd5ce8422698417",
      "value": 598635032
     }
    },
    "659db97b99b646279042826f1d92ce9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96b3eec37a294107a6d6caf4a59162b5",
      "placeholder": "​",
      "style": "IPY_MODEL_85bb5cfce2514f5bbb4587e466939910",
      "value": "config.json: 100%"
     }
    },
    "6736b80ac25e4de6bdf57a4472a84759": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68063389dddd4044af37d751819866dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e29e5323e746ec8f000b12823f337e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bb6b1bceb2e410586f2d6d07d559ee3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ee70f367ebc461eac51e9e36a4a3c38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdf06e02827f4010b979a4197cc699f8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b22c3f5e7e694683b217a723e6483d5a",
      "value": 1
     }
    },
    "702c8826bba343b394c801692e948ae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3209bb28f1e84dcc94fe83fd3eda1edc",
      "max": 694,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4523838ca360433492abec3e69e96b90",
      "value": 694
     }
    },
    "736debb8fc3f4b7ea33ef8c5c32fe1d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81a06c98028c499d85d0ddc9cbe190d0",
      "placeholder": "​",
      "style": "IPY_MODEL_a8743e4374c8493096b1d1efe61642f1",
      "value": " 1.19k/1.19k [00:00&lt;00:00, 137kB/s]"
     }
    },
    "7ed8413b46fc4118a3a1c2941cbbe607": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "806643727b2b4d499483d52b4b11339f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "812299fc10a34fd2b2352719d50edc3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81a06c98028c499d85d0ddc9cbe190d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "844b1fbf92254a84b253551b15147efa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "84bbf01d47ea4838a234edeb343b04a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_998f41c3c17545668d8ef4dcbe191462",
      "placeholder": "​",
      "style": "IPY_MODEL_0f48a0b8ae6a42ba95335ccd0515ffb8",
      "value": " 694/694 [00:00&lt;00:00, 83.4kB/s]"
     }
    },
    "85bb5cfce2514f5bbb4587e466939910": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85d76c9d595847c8b706cc9b203b9576": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88cd66a769fb42d6b15e4e5ea1d8c678": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bf023ecb55e41b8a8a85468a5b8089d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bf51b065b1e4398865fabc99ff8cb67": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d710228ca5d4fcca13ea790e9ce5702": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "900425af78e94e34b68f89dc6de7b9ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96b3eec37a294107a6d6caf4a59162b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96ea78f250b74d7fb70ba8f450ac94ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de045e8442da48bf8285fce679d73334",
      "placeholder": "​",
      "style": "IPY_MODEL_e01fa8bff8564860b30b0cfbe75d1a3d",
      "value": "Map: 100%"
     }
    },
    "97e757709f654334a1ae47c4c095e5ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "998f41c3c17545668d8ef4dcbe191462": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99d6aef8d68b42b38ea801766d2df8da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b4d9c39b63741f58284f9cdc32307c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fd0537d82884671a6ca3e53361340c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0c29430aefc43c08e6650109352ee00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a2d891fadb6e42eebfb99bf12358c95a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5476219e7124a31b0cf78931bf73d98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a5bde82622584e9a86423d57cf9bb1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35cc5f3aa2904b8fa5e9831e9d24cc05",
      "placeholder": "​",
      "style": "IPY_MODEL_cf0e5d890a374ffd9a4bb8162c2a36f4",
      "value": " 67349/0 [00:00&lt;00:00, 568541.62 examples/s]"
     }
    },
    "a8743e4374c8493096b1d1efe61642f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9c751f432404ea08c3bad5e84d176f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de08f403bf6e40acaf3ae24392d38531",
      "max": 2132967,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_095b7e03e9e643e2bd43acfdf8e371d5",
      "value": 2132967
     }
    },
    "ab109ae97ff44ad589990be27315251a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54b854d512214c97b46e0c76f742fa70",
       "IPY_MODEL_a9c751f432404ea08c3bad5e84d176f7",
       "IPY_MODEL_555e3e2bfc08489f8c7fe73fc5a814c7"
      ],
      "layout": "IPY_MODEL_0e206d47e7454eadacf7ff051df48ec5"
     }
    },
    "ae2bc8321652433cac3a0a78f15a60a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_900425af78e94e34b68f89dc6de7b9ce",
      "max": 67349,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44a2af8a27ad4bd1aee843cec5727e6a",
      "value": 67349
     }
    },
    "ae2ec05a91f5479688dfcff5268870ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c40fce8205fe4d94bd8d3112e7f4d49f",
       "IPY_MODEL_c8ff8a0cdff54269a561bb6fc983a7ef",
       "IPY_MODEL_aeff26f52ee940aba7b60c634ff7eecc"
      ],
      "layout": "IPY_MODEL_0165770850664460be47ce63ec7bb10c"
     }
    },
    "aeff26f52ee940aba7b60c634ff7eecc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49846a9589c147c3a8b6851dc4c3c573",
      "placeholder": "​",
      "style": "IPY_MODEL_3f3a82eb252249c897f0fa20827ae2f7",
      "value": " 872/0 [00:00&lt;00:00, 42400.60 examples/s]"
     }
    },
    "af7a1cd38d88456d803dbaa5463ccde1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dd44c6676f3409ab04184db47e7bf6c",
      "placeholder": "​",
      "style": "IPY_MODEL_1ec5589c6cd74477804333af9b8fce09",
      "value": " 67349/67349 [00:01&lt;00:00, 37230.30 examples/s]"
     }
    },
    "b0e2a2db5c984ecba03641211b33cdc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_99d6aef8d68b42b38ea801766d2df8da",
      "placeholder": "​",
      "style": "IPY_MODEL_6736b80ac25e4de6bdf57a4472a84759",
      "value": " 872/872 [00:00&lt;00:00, 21716.27 examples/s]"
     }
    },
    "b22c3f5e7e694683b217a723e6483d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b373907d135d4404835e49fcc0f6d979": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_844b1fbf92254a84b253551b15147efa",
      "placeholder": "​",
      "style": "IPY_MODEL_68e29e5323e746ec8f000b12823f337e",
      "value": "Generating train split: "
     }
    },
    "b4e955f9120e4b1b8fd5ce8422698417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b52ca397026d44a3b48d49454d09fff4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5819c101ac84f0787c1b40698d590c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b845f2745bde42c78682293f8f71394b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c40fce8205fe4d94bd8d3112e7f4d49f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85d76c9d595847c8b706cc9b203b9576",
      "placeholder": "​",
      "style": "IPY_MODEL_3e721409660649a08ab4d8682d49c4df",
      "value": "Generating dev split: "
     }
    },
    "c632f1c2e4d44990ba30d922632b8d87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c80645dfba284c1ca083658c327826cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8ff8a0cdff54269a561bb6fc983a7ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0c29430aefc43c08e6650109352ee00",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55a9d6374eab4a0b93c1c45a2de04254",
      "value": 1
     }
    },
    "cc26951539484e00b49d41e2d813bcba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c3b1fbc1bce47c088c76fe4ab259b55",
      "max": 4203,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2d891fadb6e42eebfb99bf12358c95a",
      "value": 4203
     }
    },
    "cd093d9855494dcf9332cea1fc9b6577": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff558352d4ca44feb2d81d1a2368fc49",
       "IPY_MODEL_702c8826bba343b394c801692e948ae7",
       "IPY_MODEL_84bbf01d47ea4838a234edeb343b04a1"
      ],
      "layout": "IPY_MODEL_c80645dfba284c1ca083658c327826cd"
     }
    },
    "cdf06e02827f4010b979a4197cc699f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "cf0e5d890a374ffd9a4bb8162c2a36f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d87ad1f3f66940a199ddac401bf78783": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26954538cb9c41dc84d36790e1bfff33",
       "IPY_MODEL_61665054dda54daca7cc78d4e89a3de8",
       "IPY_MODEL_572a5fb80e01472cbf3a0739faf21367"
      ],
      "layout": "IPY_MODEL_4914703c518c447fa8906f5c278ada32"
     }
    },
    "de045e8442da48bf8285fce679d73334": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de08f403bf6e40acaf3ae24392d38531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e01fa8bff8564860b30b0cfbe75d1a3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec734e03134c49e189454715706a1b38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4d97bf8945f343caa141904942c1bbc4",
       "IPY_MODEL_ae2bc8321652433cac3a0a78f15a60a6",
       "IPY_MODEL_af7a1cd38d88456d803dbaa5463ccde1"
      ],
      "layout": "IPY_MODEL_8bf023ecb55e41b8a8a85468a5b8089d"
     }
    },
    "f037b7aeb70043ce9b2151418f51d82b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6bb6b1bceb2e410586f2d6d07d559ee3",
      "placeholder": "​",
      "style": "IPY_MODEL_294edb60a94243628b3f423315026651",
      "value": "Downloading builder script: 100%"
     }
    },
    "fb958dc4758d4da5b8fe0c561934000d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe54f2430afa48f9994b5b23c2691299": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff558352d4ca44feb2d81d1a2368fc49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40c3721e762a4d129afa746c3016660b",
      "placeholder": "​",
      "style": "IPY_MODEL_13eca10db5c2485697b998e80041d371",
      "value": "special_tokens_map.json: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
